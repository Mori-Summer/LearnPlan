虚拟内存（Virtual Memory，VM）是现代操作系统中最核心、最精妙的内存管理技术之一。它是一种抽象层，旨在解决物理内存的局限性、简化编程，并提供强大的隔离和保护机制。本文是 C++ 底层知识系列的一部分，与《进程的内存布局》《操作系统加载可执行文件》《线程栈的位置》等文档互为补充。

---

## 核心概念：虚拟地址空间

虚拟内存的核心在于它为每个运行中的进程提供了一个独立、连续、私有的虚拟地址空间 (Virtual Address Space)。

- 隔离性（Protection）： 每个进程都认为自己独占了整个地址空间（例如 32 位系统下的4GB）。一个进程对它自己的虚拟地址空间的访问不会影响到其他进程，从而实现了进程隔离和安全性。
- 统一性（Uniformity）： 操作系统可以将物理内存中不连续的、分散的存储区域，通过虚拟内存机制，呈现给程序一个逻辑上连续的地址空间。

### 1. 虚拟地址 (VA) 与 物理地址 (PA)

- 虚拟地址 (VA)： 程序员在代码中使用的地址，CPU 执行指令时产生的地址。它是逻辑上的概念。
- 物理地址 (PA)： 内存条（RAM）上的实际地址，用于访问真实的存储单元。它是硬件上的概念。

### 2. 地址翻译（Address Translation）

虚拟内存机制的核心工作是地址翻译（Address Translation），即将 VA 转换为 PA。

- 硬件组件： 这一转换过程主要由 CPU 内部的内存管理单元 (MMU) 硬件来完成。
- 软件组件： 转换所需的查找表（页表）由操作系统（OS）内核维护。

---

## 虚拟内存的实现机制：分页 (Paging)

虚拟内存最主要的实现方式是分页机制。

### 1. 页 (Page) 与 帧 (Frame)

- 页（Page）： 虚拟地址空间被划分为固定大小的块，称为"页"（Page，通常 4KB）。
- 帧（Frame）： 物理内存也被划分为与页大小相同的块，称为"帧"（Frame）。

### 2. 页表 (Page Table)

- 作用： 操作系统为每个进程维护一个页表。页表记录了该进程虚拟地址空间中的每个页（Page）当前对应到物理内存中的哪个帧（Frame）。
- 页表条目（PTE）： 页表中的每一行（PTE）包含：
	- **帧号（Frame Number）** —— 对应的物理内存帧的地址。
	- **有效位（Valid Bit）** —— 指示该页当前是否在物理内存中。
	- **保护位（Protection Bits）** —— 定义该页的访问权限（只读、读写、可执行等）。
	- **脏位（Dirty Bit）** —— 指示该页自加载到内存后是否被修改过。OS 在换出页面时，只有脏页才需要写回磁盘，干净页可以直接丢弃。
	- **访问位（Accessed Bit）** —— 指示该页最近是否被访问过。OS 利用此位来实现页面置换算法（如 Clock 算法），判断哪些页是"不活跃"的候选换出对象。

### 3. 多级页表（Multi-level Page Tables）

上面描述的是一个简单的"平坦"页表模型。但在实际系统中，平坦页表存在严重的空间浪费问题：

- **问题**： 以 32 位系统为例，4GB 地址空间 / 4KB 页大小 = 2²⁰ 个页表条目。如果每个 PTE 占 4 字节，仅一个进程的页表就需要 **4MB** 内存。然而，大多数进程只使用了地址空间中很小的一部分（栈、堆、代码段等），绝大多数 PTE 指向"无效"。对于 64 位系统，平坦页表更是完全不可行（2⁴⁸ / 4KB = 2³⁶ 个条目）。
- **解决思路**： 将页表本身也分页，形成多级层次结构。只为实际使用的地址范围分配下级页表，未使用的区域无需分配。

#### A. 二级页表（32 位系统）

32 位虚拟地址被分为三部分：

| 位段 | 宽度 | 作用 |
|------|------|------|
| 页目录索引（Page Directory Index） | 10 位 | 索引一级页表（页目录），共 1024 个条目 |
| 页表索引（Page Table Index） | 10 位 | 索引二级页表，共 1024 个条目 |
| 页内偏移（Offset） | 12 位 | 4KB 页内的字节偏移 |

页目录始终存在（仅 4KB），但只有被实际使用的虚拟地址区域才会分配对应的二级页表。对于一个典型的进程，实际分配的页表内存远小于 4MB。

#### B. 四级页表（64 位系统，x86-64）

当前 x86-64 架构使用 48 位虚拟地址，分为五部分：

| 位段 | 宽度 | 名称 |
|------|------|------|
| PGD 索引 | 9 位 | 页全局目录（Page Global Directory） |
| PUD 索引 | 9 位 | 页上级目录（Page Upper Directory） |
| PMD 索引 | 9 位 | 页中间目录（Page Middle Directory） |
| PTE 索引 | 9 位 | 页表条目（Page Table Entry） |
| 页内偏移 | 12 位 | 4KB 页内的字节偏移 |

每级页表有 512 个条目（2⁹），每个条目 8 字节，因此每级页表恰好占一个 4KB 页。较新的处理器还支持 **五级页表**（LA57），将虚拟地址扩展到 57 位（128PB）。

#### 对比总结

| 页表类型 | 层级数 | 适用系统 | 单进程页表内存开销 |
|----------|--------|----------|------------------|
| 平坦页表 | 1 | 理论模型 | 固定且巨大（32 位：4MB，64 位：不可行） |
| 二级页表 | 2 | 32 位 x86 | 最小 4KB（仅页目录），按需增长 |
| 四级页表 | 4 | 64 位 x86-64 | 最小 4KB（仅 PGD），按需增长 |

### 4. 地址翻译流程（MMU的工作）

当 CPU 访问一个虚拟地址 V 时：

1. 解析地址： MMU 将 V 分为两部分：页号和页内偏移量。
2. 查找页表： MMU 使用页号作为索引，去查找当前进程的页表（在多级页表中，需要逐级走查）。
3. 检查有效位：
	1. 如果有效位为 1，MMU 提取对应的帧号。
	2. 如果有效位为 0，则触发**缺页中断（Page Fault）**，将控制权交给操作系统。OS 负责从磁盘加载缺失的页；如果物理内存已满，则需要通过**页面置换算法**选择一个牺牲页进行换出（详见后文"页面置换与系统行为"一节）。

4. 计算物理地址： MMU 将帧号与页内偏移量组合起来，得到最终的物理地址 P。
5. 访问内存： MMU 将物理地址 P 发送到内存总线，完成对物理内存的访问。

### 5. TLB：地址翻译的加速器（Translation Lookaside Buffer）

多级页表解决了空间问题，却引入了新的性能问题：每次地址翻译需要 2～4 次额外的内存访问（逐级走查页表）。如果每条指令都要付出这样的代价，CPU 的性能将大打折扣。

**TLB（翻译后备缓冲区）** 是 MMU 内部的一块小型高速缓存，专门用于缓存最近使用过的"虚拟页号 → 物理帧号"映射。

#### TLB 的结构

- TLB 通常是**全相联（Fully Associative）**或**组相联（Set Associative）**的缓存。
- 典型容量：L1 dTLB 约 64～128 条目，L2 TLB 约 512～2048 条目。
- 每个条目存储一个虚拟页号到物理帧号的映射，以及权限位。

#### TLB 的工作流程

```
VA → TLB 查找
      ├─ 命中（TLB Hit）→ 直接返回物理帧号 → 组合偏移 → PA（约 1 个时钟周期）
      └─ 未命中（TLB Miss）→ 执行多级页表走查（数十～数百个时钟周期）
                             → 将结果写入 TLB → PA
```

#### TLB 刷新与上下文切换

当操作系统进行**进程上下文切换**时，由于新进程拥有不同的页表，TLB 中旧进程的映射变得无效。处理方式有两种：

- **全量刷新（Flush）**： 清空整个 TLB。简单但代价高——新进程启动后会经历大量 TLB Miss。
- **ASID/PCID 标记**： 现代 CPU 支持为 TLB 条目添加**地址空间标识符（ASID）**或**进程上下文标识符（PCID）**。不同进程的映射可以同时存在于 TLB 中，避免了切换时的全量刷新。

> TLB 的容量有限，因此覆盖范围受限于页大小。使用 4KB 页时，128 个 TLB 条目仅能覆盖 512KB 内存。使用 **2MB 大页** 则可覆盖 256MB——这正是大页技术的核心优势之一（详见后文"大页"一节）。

---

## 虚拟内存的优势和作用

虚拟内存技术带来了现代计算机系统必不可少的几大优势：

### 1. 扩充内存容量的假象（使用磁盘作为后备存储）

- 后备存储 (Backing Store)： 当物理内存（RAM）满时，操作系统可以将 RAM 中不常用（不活跃）的页 换出（Swap Out）到硬盘上的交换空间（Swap Space）中。
- 按需调页 (Demand Paging)： 只有当程序需要访问被换出的页时，OS 才会触发缺页中断，将该页从磁盘 换入（Swap In）到 RAM 中。
- 效果： 程序可以运行比物理内存容量更大的任务，虽然访问磁盘会慢得多，但系统不会崩溃。

### 2. 内存隔离与保护

- 私有空间： 每个进程都有独立的页表，这意味着一个进程的虚拟地址 0x1000 和另一个进程的虚拟地址 0x1000 几乎总是映射到不同的物理地址。
- 权限控制： 通过页表中的保护位，OS 可以控制进程对特定内存区域的访问权限（如代码段只允许执行，不允许写入），从而防止恶意程序或程序错误破坏操作系统内核或其他进程的数据。

### 3. 简化内存管理

- 连续性错觉： 程序员无需关心物理内存是否连续或碎片化。OS 负责将逻辑上连续的虚拟内存页映射到物理内存中不连续的帧上。
- 共享库： 多个进程可以共享同一个物理内存区域，例如共享动态链接库（DLL/SO）的代码。OS 只需要将不同进程的虚拟地址映射到同一个物理帧即可，极大地节省了内存。（关于共享库如何通过 `mmap` 加载到进程地址空间，详见下文"内存映射文件"一节。）

---

## 页面置换与系统行为

当物理内存不足、需要为新页面腾出空间时，操作系统必须决定将哪些已在内存中的页面换出到磁盘。这一决策由**页面置换算法**完成。

### 1. 页面置换算法（Page Replacement Algorithms）

#### FIFO（先进先出）

最早被加载到内存中的页面最先被换出。实现简单，但性能差——一个长期频繁使用的页面仅仅因为"资历老"就可能被换出。FIFO 还存在**Belady 异常**：在某些访问模式下，增加物理帧数反而导致缺页次数增多。

#### LRU（最近最少使用，Least Recently Used）

换出最长时间未被访问的页面。理论上接近最优，但精确实现需要在每次内存访问时记录时间戳，硬件代价过高，因此实际系统使用近似算法。

#### Clock（时钟算法 / 二次机会算法）

LRU 的实用近似。所有页面组成一个循环链表，一个"指针"（时钟的指针）顺序扫描：

1. 检查当前页面的**访问位（Accessed Bit）**。
2. 如果访问位为 1，将其清零，指针移向下一个页面（给它"第二次机会"）。
3. 如果访问位为 0，选择该页面作为牺牲页换出。

Linux 内核实际使用的是 Clock 的增强版本——**活跃/非活跃链表（Active/Inactive List）**机制，将页面分为活跃和非活跃两个链表，优先从非活跃链表中回收。

#### 算法对比

| 算法 | 实现复杂度 | 性能 | Belady 异常 |
|------|-----------|------|------------|
| FIFO | 低 | 差 | 存在 |
| LRU | 高（精确实现） | 好 | 不存在 |
| Clock | 低 | 接近 LRU | 不存在 |

### 2. 颠簸（Thrashing）与工作集（Working Set）

#### 颠簸

当系统中运行的进程过多，所有进程的**活跃页面总量**超过了物理内存容量时，系统进入**颠簸（Thrashing）**状态：

- 页面被换入后几乎立即被换出，为其他进程腾出空间。
- 大量 CPU 时间消耗在处理缺页中断和磁盘 I/O 上。
- 表现为：**缺页率极高、Swap 使用率飙升、CPU 利用率反而很低**（因为进程都在等待 I/O）。

#### 工作集模型（Working Set Model）

- **工作集**是指一个进程在某个时间窗口 Δ 内实际访问的页面集合。
- 如果操作系统能确保每个进程至少拥有其工作集大小的物理帧，就可以避免颠簸。
- 当总工作集超过物理内存时，OS 应暂停（挂起）部分进程，而非让所有进程一起颠簸。

#### 缓解颠簸的手段

- 减少并发运行的进程数量
- 增加物理内存（RAM）
- 优化程序的数据访问模式，提高**局部性（Locality）**
- 使用 SSD 替代 HDD 作为 Swap 设备（降低换入换出的延迟）

---

## 虚拟内存的高级机制

### 1. 写时复制（Copy-on-Write, COW）

当一个进程调用 `fork()` 创建子进程时，子进程需要获得父进程地址空间的完整副本。如果真的复制所有页面，开销将非常大。**写时复制（COW）**是对此的关键优化：

1. **fork() 时**：父子进程共享相同的物理帧，双方的页表条目都被标记为**只读**。
2. **写入时**：当任一进程尝试写入某个共享页面时，MMU 检测到权限违规，触发缺页中断。OS 识别出这是一个 COW 页面，于是分配一个新的物理帧，复制原页面内容，更新写入方的 PTE 指向新帧并恢复写权限。
3. **效果**：只有被实际修改的页面才会被复制，代码段等只读页面始终共享。

COW 对 Unix/Linux 系统的 **fork + exec** 模式至关重要——`fork()` 后子进程通常立即调用 `exec()` 加载新程序，此时父进程的大部分页面根本不会被子进程写入，COW 避免了大量无意义的内存复制。

### 2. 大页（Large Pages / Huge Pages）

#### 动机

标准 4KB 页在面对大内存应用时存在 TLB 覆盖不足的问题：

| 页大小 | 覆盖 1GB 内存所需页数 | 所需 TLB 条目数 | 页表层级 |
|--------|----------------------|----------------|---------|
| 4KB | 262,144 | 262,144 | 4 |
| 2MB | 512 | 512 | 3（跳过 PTE 级） |
| 1GB | 1 | 1 | 2（跳过 PMD 和 PTE 级） |

#### 实现原理

x86-64 通过在页表的 PMD 级（2MB 页）或 PUD 级（1GB 页）设置 **PS（Page Size）位**，直接将该条目作为最终映射，跳过下级页表的走查。

#### Linux 中的使用方式

- **显式大页（HugeTLB）**：通过 `hugetlbfs` 文件系统或 `mmap` 的 `MAP_HUGETLB` 标志申请。需要预先配置系统保留的大页数量。
- **透明大页（THP, Transparent Huge Pages）**：内核自动将连续的 4KB 页合并为 2MB 大页，对应用程序透明。但 THP 的后台合并/拆分操作可能引入延迟抖动。

#### 权衡

- **优势**：显著减少 TLB 未命中，提升数据库、科学计算等大内存应用的性能。
- **劣势**：增加**内部碎片**（如果只用了 2MB 页中的几 KB，剩余空间浪费）；THP 的后台 compaction 可能导致延迟毛刺。

### 3. 内存映射文件（Memory-Mapped Files, mmap）

`mmap()` 系统调用将一个文件（或其部分内容）直接映射到进程的虚拟地址空间中。访问该虚拟地址区域时，MMU 会按需触发缺页中断，由内核从磁盘加载对应的文件内容到物理内存——与按需调页的机制完全一致。

#### 两种映射模式

- **MAP_SHARED（共享映射）**：多个进程映射同一文件时共享相同的物理帧；对映射区域的修改会写回文件，其他进程可见。
- **MAP_PRIVATE（私有映射）**：对映射区域的修改通过 COW 机制处理——写入时复制一份私有副本，不影响原文件，也不影响其他进程。

#### 优势与用例

- **避免显式 I/O 调用**：不需要 `read()`/`write()` 系统调用，内核的页缓存（Page Cache）直接服务于内存访问。
- **共享内存**：`MAP_SHARED` 配合匿名映射（`MAP_ANONYMOUS`）是进程间通信（IPC）的高效手段。
- **实际应用**：数据库引擎（SQLite、LMDB）、日志文件随机访问、大文件处理。
- **动态库加载**：操作系统加载共享库（`.so`/`.dll`）本质上就是通过 `mmap` 将库文件映射到进程地址空间（详见《操作系统加载可执行文件》）。

---

## 虚拟内存与安全

### 1. ASLR（地址空间布局随机化，Address Space Layout Randomization）

#### 问题

在早期操作系统中，进程的栈、堆、共享库、代码段的虚拟地址是**固定且可预测的**。攻击者可以利用缓冲区溢出等漏洞，精准跳转到已知地址执行恶意代码（如 return-to-libc 攻击、ROP 攻击）。

#### ASLR 机制

ASLR 在每次进程启动时，随机化以下区域的基地址：

- **栈（Stack）**的起始地址
- **堆（Heap）**的起始地址
- **mmap 区域**（共享库、匿名映射）的基地址
- **主程序代码段**（需要编译为 **PIE——位置无关可执行文件**）

这使得攻击者无法提前知道目标函数或数据的虚拟地址，大幅增加了利用难度。

#### ASLR 与虚拟内存的关系

ASLR 之所以可行，正是因为虚拟内存的存在——每个进程拥有独立的地址空间，OS 可以将各段放置在任意虚拟地址，通过页表映射到物理内存，而不影响程序的正确执行。

#### 局限性

ASLR 并非万能。信息泄露漏洞（如格式化字符串漏洞）可以暴露运行时地址，绕过 ASLR。因此，ASLR 通常与其他防御机制配合使用：

- **DEP/NX（数据执行保护）**：将数据页标记为不可执行
- **栈金丝雀（Stack Canary）**：检测栈缓冲区溢出
- **RELRO（Relocation Read-Only）**：将 GOT 表标记为只读

---

## 32位和64位系统中的虚拟地址

虚拟内存与 32 位和 64 位系统的关联，是计算机体系结构中一个最根本的区别，它直接定义了一个进程可以拥有多大的虚拟地址空间。

这里的 "位"（bitness）主要指 CPU 的寄存器宽度和它能够处理的地址宽度。

### 1. 虚拟地址空间的上限

虚拟内存地址空间的大小由 CPU 的地址总线宽度（即 32 位或 64 位）来决定。

#### A. 32 位系统

- 地址宽度： 32 位（2³²）。
- 最大虚拟地址空间： 2³² 字节 ≈4GB。

这意味着，无论计算机实际安装了多少物理内存（RAM），每个进程的虚拟地址空间上限就是 4GB。

- 内核/用户空间划分： 在 32 位系统中，这 4GB 必须在用户空间（给程序使用）和内核空间（给操作系统内核使用）之间进行划分。

- 典型划分（Linux/Windows）： 常见的是 3GB 用户空间 + 1GB 内核空间，或 2GB 用户空间 + 2GB 内核空间。
- 限制： 单个应用程序能使用的最大内存（堆、栈、代码等总和）被严格限制在这个用户空间大小内（通常 <4GB）。

#### B. 64 位系统

- 地址宽度： 64 位（2⁶⁴）。
- 最大虚拟地址空间： 2⁶⁴ 字节 ≈18.4 EB（Exabytes，艾字节，即亿亿字节）。

虽然 CPU 理论上支持 64 位的地址，但由于实际需求和工程上的复杂性，当前的 64 位操作系统（如 Windows/Linux）通常只使用 48 位或 52 位的虚拟地址空间，这仍然是一个巨大的数字（例如 2⁴⁸=256TB）。

- 用户空间： 在 64 位系统中，单个应用程序可以使用的虚拟地址空间高达数十 TB 甚至数百 TB，彻底解决了 32 位系统 4GB 的内存限制。
- 内核/用户空间： 64 位系统通常将巨大的虚拟地址空间一分为二，高地址部分给内核，低地址部分给用户进程，彼此互不干扰。

---

### 2. 内存限制和物理内存（RAM）的关系

"32 位系统最多只能使用 4GB 物理内存"的说法，就是源于这个虚拟地址空间的限制。

| 系统 | 进程最大虚拟地址空间 | 系统最大物理内存 (RAM) |
| ---- | ---------- | -------------------------------------------------------- |
| 32 位 | ≈ 4GB | 操作系统无法为超出 4GB 的物理内存进行完整的地址映射，因此实际可用 RAM 仅为 3.2GB∼4GB 左右。 |
| 64 位 | ≈ 数百 TB | 可以轻松映射和管理 数百 GB 乃至数 TB 的物理 RAM。 |

- 注意：PAE（Physical Address Extension）： Windows 和 Linux 在 32 位系统上引入了 PAE 技术，允许 CPU 使用 36 位甚至更宽的物理地址来访问超过 4GB 的 RAM。但即使使用了 PAE，单个 32 位进程的虚拟地址空间仍然限制在 4GB。

---

### 3. 兼容性（WOW64 机制）

64 位系统通常具有向后兼容性，可以运行 32 位应用程序，这在虚拟内存层面是通过 WOW64（Windows on Windows64）或类似的兼容层实现的：

1. 隔离的 4GB 空间： 64 位操作系统在巨大的 64 位虚拟地址空间中，为 32 位应用划出一个独立的、严格限制在 4GB 范围内的"虚拟地址空间"。
2. 地址翻译： CPU 依然执行 64 位的地址翻译，但 32 位应用生成的地址（只有 32 位长）会被映射到 64 位空间中的这个特定 4GB 区域内。
3. 结论： 32 位程序运行在 64 位系统上时，依然受限于 4GB 的虚拟地址空间，无法利用 64 位系统提供的全部巨大内存。

---

## 虚拟内存与 C++ 编程实践

### 1. new/delete 与虚拟内存

当 C++ 程序调用 `new` 分配内存时，底层发生了一系列与虚拟内存相关的操作：

1. `new` 调用 `operator new`，通常最终调用 `malloc`。
2. `malloc`（以 glibc 为例）根据申请大小选择不同策略：
	- **小分配（通常 < 128KB）**：通过 `brk()`/`sbrk()` 扩展堆段的虚拟地址范围。
	- **大分配（通常 ≥ 128KB）**：通过 `mmap()` 在独立的虚拟地址区域分配。
3. 无论哪种方式，OS 仅更新页表中的虚拟地址映射，**物理帧直到首次访问时才分配**（按需调页）。

调用 `delete` 时，内存被归还给分配器的空闲链表。分配器**可能不会**立即通过 `munmap` 或 `brk` 缩减将虚拟地址归还给 OS——它会保留这些虚拟地址以备后续分配。这就是为什么在 `top`/`htop` 中，一个 C++ 程序的 **VIRT（虚拟内存大小）**往往远大于 **RSS（驻留集大小）**，这并不一定是内存泄漏。

### 2. 栈、堆与地址空间

- **栈（Stack）**：每个线程在虚拟地址空间中拥有一块连续区域作为栈（通常 1～8MB）。栈的虚拟页在线程创建时映射，物理帧按需分配。栈底部通常有一个**守护页（Guard Page）**，其权限设为不可读写——当栈溢出触碰到守护页时，会产生段错误，而非悄悄覆盖其他数据。
- **堆（Heap）**：通过 `brk()` 或 `mmap()` 增长。glibc 的 `malloc` 对大块分配直接使用 `mmap()`，这些区域位于内存映射段而非传统堆段。

> 关于栈、堆、代码段等在地址空间中的具体布局，详见《进程的内存布局》。关于线程栈的分配位置，详见《线程栈的位置》。

### 3. 段错误（Segmentation Fault）的本质

段错误是 C++ 程序中最常见的崩溃类型之一，其本质是虚拟内存保护机制在发挥作用：

1. 程序访问一个虚拟地址。
2. MMU 在页表中发现该地址**未映射**（无有效 PTE），或该访问**违反了保护位**（如向只读页写入）。
3. MMU 触发**缺页异常**，OS 检查后判定这不是一个合法的按需调页请求。
4. OS 向进程发送 **SIGSEGV** 信号，进程默认终止并可生成核心转储（Core Dump）。

**常见的 C++ 触发场景**：
- **解引用空指针或悬空指针**：地址 0x0 或已释放的地址未在页表中映射。
- **栈溢出**：访问超出守护页的地址。
- **写入字符串字面量**：字符串字面量存储在 `.rodata` 段，该段页表条目标记为只读。

---

## 实用工具：观察虚拟内存

### 1. Linux 工具

| 工具 | 用途 | 常用命令 |
|------|------|---------|
| `/proc/[pid]/maps` | 查看进程的所有虚拟内存区域（VMA） | `cat /proc/<pid>/maps` |
| `pmap` | 更友好地展示进程的虚拟内存映射及 RSS | `pmap -x <pid>` |
| `vmstat` | 系统级虚拟内存统计（缺页、Swap 等） | `vmstat 1`（每秒刷新） |
| `/proc/meminfo` | 系统总体内存信息 | `cat /proc/meminfo` |
| `top`/`htop` | 进程级内存概览 | 关注 VIRT、RES、SHR 列 |

**`top`/`htop` 中的内存列含义**：
- **VIRT**：进程的虚拟地址空间总大小，包括已映射但未分配物理帧的区域。
- **RES（RSS）**：进程实际占用的物理内存大小（驻留集）。
- **SHR**：与其他进程共享的物理页大小（如共享库）。

### 2. 示例：查看进程的虚拟内存映射

以下是 `cat /proc/self/maps` 的典型输出（已简化）：

```
地址范围                  权限  偏移     设备  inode   路径
55d3a4400000-55d3a4402000 r--p 00000000 08:01 131073 /usr/bin/cat     ← 代码段（只读）
55d3a4402000-55d3a4407000 r-xp 00002000 08:01 131073 /usr/bin/cat     ← 代码段（可执行）
55d3a4407000-55d3a440a000 r--p 00007000 08:01 131073 /usr/bin/cat     ← 只读数据
55d3a440a000-55d3a440b000 rw-p 00009000 08:01 131073 /usr/bin/cat     ← 可读写数据段
55d3a5c00000-55d3a5c21000 rw-p 00000000 00:00 0      [heap]           ← 堆
7f2a8c000000-7f2a8c1c0000 r--p 00000000 08:01 262146 /lib/libc.so.6   ← 共享库（mmap）
7ffd4bc00000-7ffd4bc21000 rw-p 00000000 00:00 0      [stack]          ← 栈
```

**权限字段含义**：`r` 可读、`w` 可写、`x` 可执行、`p` 私有映射 / `s` 共享映射。每一行对应虚拟地址空间中的一个连续区域（VMA），其权限由页表中的保护位控制。
