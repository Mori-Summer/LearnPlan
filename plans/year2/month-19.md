# Month 19: çº¿ç¨‹æ± è®¾è®¡ä¸å®ç°â€”â€”é«˜æ•ˆä»»åŠ¡è°ƒåº¦

## æœ¬æœˆä¸»é¢˜æ¦‚è¿°

çº¿ç¨‹æ± æ˜¯ç®¡ç†å¹¶å‘ä»»åŠ¡çš„æ ¸å¿ƒç»„ä»¶ï¼Œä¹Ÿæ˜¯ç°ä»£é«˜æ€§èƒ½ç³»ç»Ÿçš„åŸºç¡€è®¾æ–½ã€‚æœ¬æœˆå°†ä»åŸºç¡€æ¶æ„å¼€å§‹ï¼Œé€æ­¥æ·±å…¥åˆ°å·¥ä½œçªƒå–ã€ä»»åŠ¡ä¼˜å…ˆçº§ã€åŠ¨æ€æ‰©ç¼©å®¹ç­‰é«˜çº§ç‰¹æ€§ï¼Œæœ€ç»ˆå®ç°ä¸€ä¸ªç”Ÿäº§çº§çš„çº¿ç¨‹æ± ã€‚

**ä¸ºä»€ä¹ˆçº¿ç¨‹æ± å¦‚æ­¤é‡è¦ï¼Ÿ**
- é¿å…é¢‘ç¹åˆ›å»º/é”€æ¯çº¿ç¨‹çš„å¼€é”€ï¼ˆçº¿ç¨‹åˆ›å»ºé€šå¸¸éœ€è¦æ•°åå¾®ç§’ï¼‰
- æ§åˆ¶ç³»ç»Ÿèµ„æºä½¿ç”¨ï¼Œé˜²æ­¢çº¿ç¨‹çˆ†ç‚¸
- æä¾›ç»Ÿä¸€çš„ä»»åŠ¡è°ƒåº¦å’Œç®¡ç†æ¥å£
- æ˜¯å¼‚æ­¥ç¼–ç¨‹ã€å¹¶è¡Œè®¡ç®—ã€æœåŠ¡å™¨æ¶æ„çš„åŸºç¡€

---

## å­¦ä¹ ç›®æ ‡ä¸éªŒæ”¶æ ‡å‡†

| ç›®æ ‡ç¼–å· | å­¦ä¹ ç›®æ ‡ | éªŒæ”¶æ ‡å‡† |
|---------|---------|---------|
| W1-G1 | ç†è§£çº¿ç¨‹æ± æ ¸å¿ƒç»„ä»¶ | èƒ½ç‹¬ç«‹è®¾è®¡ä»»åŠ¡é˜Ÿåˆ—ã€å·¥ä½œçº¿ç¨‹ã€æäº¤æ¥å£ |
| W1-G2 | æŒæ¡ä»»åŠ¡ç»“æœè·å– | æ­£ç¡®ä½¿ç”¨ future/promise/packaged_task |
| W1-G3 | å®ç°ä¼˜é›…å…³é—­ | èƒ½å¤„ç†å…³é—­æ—¶çš„ä»»åŠ¡æ¸…ç†å’Œçº¿ç¨‹å›æ”¶ |
| W2-G1 | ç†è§£å·¥ä½œçªƒå–åŸç† | èƒ½è§£é‡Šä¸ºä»€ä¹ˆå·¥ä½œçªƒå–èƒ½æé«˜è´Ÿè½½å‡è¡¡ |
| W2-G2 | å®ç°æ— é”å·¥ä½œçªƒå–é˜Ÿåˆ— | æ­£ç¡®å®ç° Chase-Lev deque |
| W2-G3 | æŒæ¡ Fork/Join æ¨¡å¼ | èƒ½ç”¨å·¥ä½œçªƒå–å®ç°é€’å½’å¹¶è¡Œç®—æ³• |
| W3-G1 | å®ç°ä¼˜å…ˆçº§è°ƒåº¦ | æ”¯æŒå¤šç§ä¼˜å…ˆçº§ç­–ç•¥ |
| W3-G2 | å®ç°ä»»åŠ¡ä¾èµ–å›¾ | æ­£ç¡®å¤„ç† DAG å½¢å¼çš„ä»»åŠ¡ä¾èµ– |
| W3-G3 | å®ç°å»¶è¿Ÿä»»åŠ¡ | æ”¯æŒå®šæ—¶æ‰§è¡Œå’Œå‘¨æœŸæ‰§è¡Œ |
| W4-G1 | å®ç°åŠ¨æ€æ‰©ç¼©å®¹ | æ ¹æ®è´Ÿè½½è‡ªåŠ¨è°ƒæ•´çº¿ç¨‹æ•° |
| W4-G2 | æŒæ¡ç›‘æ§ä¸è°ƒä¼˜ | èƒ½æ”¶é›†å’Œåˆ†æçº¿ç¨‹æ± æ€§èƒ½æŒ‡æ ‡ |
| W4-G3 | äº†è§£ç”Ÿäº§çº§å®è·µ | ç†è§£ä¸»æµçº¿ç¨‹æ± å®ç°çš„è®¾è®¡æƒè¡¡ |

---

## ç†è®ºå­¦ä¹ å†…å®¹

### ç¬¬ä¸€å‘¨ï¼šçº¿ç¨‹æ± åŸºç¡€æ¶æ„

**å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡çº¿ç¨‹æ± çš„æ ¸å¿ƒç»„ä»¶è®¾è®¡ï¼Œå®ç°ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„åŸºç¡€çº¿ç¨‹æ± 

**é˜…è¯»ææ–™**ï¼š
- [ ] ã€ŠC++ Concurrency in Actionã€‹ç¬¬9ç« 
- [ ] CppCon 2015: "C++ Multithreading" by Fedor Pikus
- [ ] åšå®¢ï¼šAnthony Williams "Implementing a Thread-Safe Queue"
- [ ] è®ºæ–‡ï¼šHerb Sutter "The Free Lunch Is Over"

---

#### ğŸ“… Day 1-2: çº¿ç¨‹æ± æ ¸å¿ƒç»„ä»¶è®¾è®¡ï¼ˆ10å°æ—¶ï¼‰

**Day 1 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- æ¶æ„è®¾è®¡**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:00 | éœ€æ±‚åˆ†æ | åˆ—å‡ºçº¿ç¨‹æ± éœ€è¦æ”¯æŒçš„åŠŸèƒ½ï¼šæäº¤ä»»åŠ¡ã€è·å–ç»“æœã€å…³é—­ç­‰ |
| 1:00-2:00 | ç»„ä»¶è¯†åˆ« | ç†è§£å››å¤§æ ¸å¿ƒç»„ä»¶ï¼šä»»åŠ¡é˜Ÿåˆ—ã€å·¥ä½œçº¿ç¨‹ã€æäº¤æ¥å£ã€ç”Ÿå‘½å‘¨æœŸç®¡ç† |
| 2:00-2:30 | æ¥å£è®¾è®¡ | è®¾è®¡ ThreadPool çš„å…¬å…±æ¥å£ |

**Day 1 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- ä»»åŠ¡é˜Ÿåˆ—å®ç°**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | çº¿ç¨‹å®‰å…¨é˜Ÿåˆ— | å®ç°åŸºäº mutex + condition_variable çš„ä»»åŠ¡é˜Ÿåˆ— |
| 1:30-2:30 | æµ‹è¯•éªŒè¯ | ç¼–å†™å¤šçº¿ç¨‹é˜Ÿåˆ—æµ‹è¯• |

**æ ¸å¿ƒæ¦‚å¿µï¼šçº¿ç¨‹æ± æ¶æ„å›¾**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ThreadPool                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Client    â”‚    â”‚           Task Queue                 â”‚ â”‚
â”‚  â”‚  (submit)   â”‚â”€â”€â”€â–¶â”‚  [Task1] [Task2] [Task3] ...        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚         â–¼                          â–¼                      â–¼ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Worker 1  â”‚            â”‚  Worker 2  â”‚   ...    â”‚Worker Nâ”‚â”‚
â”‚  â”‚  (thread)  â”‚            â”‚  (thread)  â”‚          â”‚(thread)â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**åŠ¨æ‰‹å®éªŒ 1-1ï¼šçº¿ç¨‹å®‰å…¨ä»»åŠ¡é˜Ÿåˆ—**
```cpp
// thread_safe_queue.hpp
#pragma once
#include <queue>
#include <mutex>
#include <condition_variable>
#include <optional>

template <typename T>
class ThreadSafeQueue {
    std::queue<T> queue_;
    mutable std::mutex mutex_;
    std::condition_variable cv_;
    bool stopped_ = false;

public:
    // æ·»åŠ ä»»åŠ¡
    void push(T item) {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            if (stopped_) {
                throw std::runtime_error("Queue is stopped");
            }
            queue_.push(std::move(item));
        }
        cv_.notify_one();
    }

    // é˜»å¡è·å–ä»»åŠ¡
    std::optional<T> pop() {
        std::unique_lock<std::mutex> lock(mutex_);
        cv_.wait(lock, [this] {
            return !queue_.empty() || stopped_;
        });

        if (queue_.empty()) {
            return std::nullopt;  // é˜Ÿåˆ—å·²åœæ­¢ä¸”ä¸ºç©º
        }

        T item = std::move(queue_.front());
        queue_.pop();
        return item;
    }

    // éé˜»å¡å°è¯•è·å–
    std::optional<T> try_pop() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (queue_.empty()) {
            return std::nullopt;
        }
        T item = std::move(queue_.front());
        queue_.pop();
        return item;
    }

    // åœæ­¢é˜Ÿåˆ—
    void stop() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            stopped_ = true;
        }
        cv_.notify_all();
    }

    bool empty() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return queue_.empty();
    }

    size_t size() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return queue_.size();
    }
};
```

**Day 2 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- å·¥ä½œçº¿ç¨‹å®ç°**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | å·¥ä½œçº¿ç¨‹å¾ªç¯ | å®ç°ä»é˜Ÿåˆ—å–ä»»åŠ¡å¹¶æ‰§è¡Œçš„å¾ªç¯ |
| 1:30-2:30 | å¼‚å¸¸å¤„ç† | ç¡®ä¿ä»»åŠ¡å¼‚å¸¸ä¸ä¼šç»ˆæ­¢å·¥ä½œçº¿ç¨‹ |

**Day 2 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- åŸºç¡€çº¿ç¨‹æ± æ•´åˆ**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | å®Œæ•´å®ç° | æ•´åˆé˜Ÿåˆ—å’Œå·¥ä½œçº¿ç¨‹ï¼Œå®ç°åŸºç¡€çº¿ç¨‹æ±  |
| 2:00-2:30 | åŸºç¡€æµ‹è¯• | éªŒè¯åŸºæœ¬çš„ä»»åŠ¡æäº¤å’Œæ‰§è¡Œ |

**åŠ¨æ‰‹å®éªŒ 1-2ï¼šåŸºç¡€çº¿ç¨‹æ± **
```cpp
// basic_thread_pool.hpp
#pragma once
#include <thread>
#include <vector>
#include <functional>
#include <atomic>
#include "thread_safe_queue.hpp"

class BasicThreadPool {
    using Task = std::function<void()>;

    ThreadSafeQueue<Task> task_queue_;
    std::vector<std::thread> workers_;
    std::atomic<bool> running_{true};

    void worker_loop() {
        while (running_) {
            auto task = task_queue_.pop();
            if (task) {
                try {
                    (*task)();
                } catch (const std::exception& e) {
                    // è®°å½•å¼‚å¸¸ä½†ä¸ç»ˆæ­¢çº¿ç¨‹
                    // ç”Ÿäº§ç¯å¢ƒåº”è¯¥æœ‰æ›´å¥½çš„é”™è¯¯å¤„ç†
                }
            }
        }
    }

public:
    explicit BasicThreadPool(size_t num_threads = std::thread::hardware_concurrency()) {
        for (size_t i = 0; i < num_threads; ++i) {
            workers_.emplace_back(&BasicThreadPool::worker_loop, this);
        }
    }

    ~BasicThreadPool() {
        shutdown();
    }

    // ç¦æ­¢æ‹·è´
    BasicThreadPool(const BasicThreadPool&) = delete;
    BasicThreadPool& operator=(const BasicThreadPool&) = delete;

    void submit(Task task) {
        task_queue_.push(std::move(task));
    }

    void shutdown() {
        if (running_.exchange(false)) {
            task_queue_.stop();
            for (auto& worker : workers_) {
                if (worker.joinable()) {
                    worker.join();
                }
            }
        }
    }

    size_t pending_tasks() const {
        return task_queue_.size();
    }
};
```

**å¸¸è§é”™è¯¯è­¦ç¤º**ï¼š
> âš ï¸ **é”™è¯¯ 1**ï¼šåœ¨ææ„å‡½æ•°ä¸­å¿˜è®° join å·¥ä½œçº¿ç¨‹
> ```cpp
> // é”™è¯¯ï¼šçº¿ç¨‹æ‚¬ç©ºï¼Œç¨‹åºå´©æºƒ
> ~BasicThreadPool() {
>     running_ = false;
>     // å¿˜è®° joinï¼
> }
> ```
>
> âš ï¸ **é”™è¯¯ 2**ï¼šä¸å¤„ç†ä»»åŠ¡ä¸­çš„å¼‚å¸¸
> ```cpp
> // é”™è¯¯ï¼šå¼‚å¸¸ä¼šç»ˆæ­¢å·¥ä½œçº¿ç¨‹
> void worker_loop() {
>     while (running_) {
>         auto task = task_queue_.pop();
>         (*task)();  // å¦‚æœæŠ›å¼‚å¸¸ï¼Œçº¿ç¨‹å°±æ­»äº†ï¼
>     }
> }
> ```

**Day 1-2 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] èƒ½è§£é‡Šçº¿ç¨‹æ± å››å¤§æ ¸å¿ƒç»„ä»¶çš„èŒè´£
- [ ] å®ç°çš„é˜Ÿåˆ—èƒ½æ­£ç¡®å¤„ç†å¤šçº¿ç¨‹å¹¶å‘è®¿é—®
- [ ] åŸºç¡€çº¿ç¨‹æ± èƒ½æ­£ç¡®æ‰§è¡Œæäº¤çš„ä»»åŠ¡
- [ ] ç†è§£ä¸ºä»€ä¹ˆéœ€è¦åœ¨ææ„æ—¶ join çº¿ç¨‹

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `thread_safe_queue.hpp`
- [ ] `basic_thread_pool.hpp`
- [ ] `test_basic_pool.cpp`
- [ ] ç¬”è®°ï¼š`notes/week1/day1-2_core_components.md`

---

#### ğŸ“… Day 3-4: ä»»åŠ¡ç»“æœè·å–æœºåˆ¶ï¼ˆ10å°æ—¶ï¼‰

**Day 3 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- future/promise æ·±å…¥ç†è§£**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:00 | å›é¡¾åŸºç¡€ | å¤ä¹  std::futureã€std::promiseã€std::shared_future |
| 1:00-2:00 | packaged_task | æ·±å…¥ç†è§£ std::packaged_task çš„åŸç† |
| 2:00-2:30 | å¯¹æ¯”åˆ†æ | åˆ†æä¸‰ç§å¼‚æ­¥ç»“æœè·å–æ–¹å¼çš„é€‚ç”¨åœºæ™¯ |

**æ ¸å¿ƒæ¦‚å¿µï¼šå¼‚æ­¥ç»“æœè·å–çš„ä¸‰ç§æ–¹å¼**
```cpp
#include <future>
#include <thread>

// æ–¹å¼1ï¼šstd::asyncï¼ˆæœ€ç®€å•ï¼Œä½†æ§åˆ¶åŠ›å¼±ï¼‰
auto future1 = std::async(std::launch::async, []{ return 42; });

// æ–¹å¼2ï¼šstd::promiseï¼ˆæœ€çµæ´»ï¼Œå®Œå…¨æ‰‹åŠ¨æ§åˆ¶ï¼‰
std::promise<int> promise;
auto future2 = promise.get_future();
std::thread([&promise]{ promise.set_value(42); }).detach();

// æ–¹å¼3ï¼šstd::packaged_taskï¼ˆé€‚åˆçº¿ç¨‹æ± åœºæ™¯ï¼‰
std::packaged_task<int()> task([]{ return 42; });
auto future3 = task.get_future();
std::thread(std::move(task)).detach();
```

**Day 3 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- æ‰©å±•çº¿ç¨‹æ± æ”¯æŒè¿”å›å€¼**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | æ¨¡æ¿submit | å®ç°è¿”å› future çš„ submit æ–¹æ³• |
| 2:00-2:30 | æµ‹è¯•éªŒè¯ | éªŒè¯å„ç§è¿”å›ç±»å‹çš„ä»»åŠ¡ |

**åŠ¨æ‰‹å®éªŒ 1-3ï¼šæ”¯æŒè¿”å›å€¼çš„çº¿ç¨‹æ± **
```cpp
// thread_pool_with_future.hpp
#pragma once
#include <thread>
#include <vector>
#include <queue>
#include <functional>
#include <future>
#include <mutex>
#include <condition_variable>
#include <type_traits>

class ThreadPoolWithFuture {
    std::queue<std::function<void()>> tasks_;
    std::vector<std::thread> workers_;
    std::mutex mutex_;
    std::condition_variable cv_;
    bool stop_ = false;

    void worker_loop() {
        while (true) {
            std::function<void()> task;
            {
                std::unique_lock<std::mutex> lock(mutex_);
                cv_.wait(lock, [this] {
                    return stop_ || !tasks_.empty();
                });

                if (stop_ && tasks_.empty()) {
                    return;
                }

                task = std::move(tasks_.front());
                tasks_.pop();
            }
            task();
        }
    }

public:
    explicit ThreadPoolWithFuture(size_t threads = std::thread::hardware_concurrency()) {
        for (size_t i = 0; i < threads; ++i) {
            workers_.emplace_back(&ThreadPoolWithFuture::worker_loop, this);
        }
    }

    ~ThreadPoolWithFuture() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            stop_ = true;
        }
        cv_.notify_all();
        for (auto& worker : workers_) {
            if (worker.joinable()) {
                worker.join();
            }
        }
    }

    // æ ¸å¿ƒï¼šæ”¯æŒä»»æ„å¯è°ƒç”¨å¯¹è±¡ï¼Œè¿”å› future
    template <typename F, typename... Args>
    auto submit(F&& f, Args&&... args)
        -> std::future<std::invoke_result_t<F, Args...>>
    {
        using ReturnType = std::invoke_result_t<F, Args...>;

        // åˆ›å»º packaged_task
        auto task = std::make_shared<std::packaged_task<ReturnType()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...)
        );

        std::future<ReturnType> result = task->get_future();

        {
            std::lock_guard<std::mutex> lock(mutex_);
            if (stop_) {
                throw std::runtime_error("ThreadPool is stopped");
            }
            tasks_.emplace([task]() { (*task)(); });
        }
        cv_.notify_one();

        return result;
    }
};
```

**Day 4 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- å¼‚å¸¸ä¼ æ’­æœºåˆ¶**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:00 | å¼‚å¸¸ä¼ æ’­åŸç† | ç†è§£ future å¦‚ä½•æ•è·å’Œä¼ æ’­å¼‚å¸¸ |
| 1:00-2:00 | å®éªŒéªŒè¯ | æµ‹è¯•ä»»åŠ¡æŠ›å‡ºå¼‚å¸¸æ—¶çš„è¡Œä¸º |
| 2:00-2:30 | æœ€ä½³å®è·µ | æ•´ç†å¼‚å¸¸å¤„ç†çš„æ¨èåšæ³• |

**åŠ¨æ‰‹å®éªŒ 1-4ï¼šå¼‚å¸¸ä¼ æ’­æµ‹è¯•**
```cpp
// test_exception_propagation.cpp
#include "thread_pool_with_future.hpp"
#include <iostream>
#include <stdexcept>

void test_exception_propagation() {
    ThreadPoolWithFuture pool(4);

    // æäº¤ä¸€ä¸ªä¼šæŠ›å¼‚å¸¸çš„ä»»åŠ¡
    auto future = pool.submit([]() -> int {
        throw std::runtime_error("Task failed!");
        return 42;
    });

    try {
        int result = future.get();  // è¿™é‡Œä¼šé‡æ–°æŠ›å‡ºå¼‚å¸¸
        std::cout << "Result: " << result << "\n";
    } catch (const std::exception& e) {
        std::cout << "Caught exception: " << e.what() << "\n";
    }

    // æ­£å¸¸ä»»åŠ¡
    auto future2 = pool.submit([]{ return 100; });
    std::cout << "Normal result: " << future2.get() << "\n";
}

int main() {
    test_exception_propagation();
    return 0;
}
```

**Day 4 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- æ‰¹é‡ä»»åŠ¡ä¸ç­‰å¾…**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | æ‰¹é‡æäº¤ | å®ç° submit_batch æ–¹æ³• |
| 1:30-2:30 | ç­‰å¾…æ‰€æœ‰å®Œæˆ | å®ç° wait_all è¾…åŠ©å‡½æ•° |

**åŠ¨æ‰‹å®éªŒ 1-5ï¼šæ‰¹é‡ä»»åŠ¡å¤„ç†**
```cpp
// æ‰¹é‡æäº¤ä¸ç­‰å¾…çš„è¾…åŠ©å‡½æ•°
template <typename Container>
auto submit_batch(ThreadPoolWithFuture& pool, Container&& tasks) {
    using TaskType = typename std::decay_t<Container>::value_type;
    using ReturnType = std::invoke_result_t<TaskType>;

    std::vector<std::future<ReturnType>> futures;
    futures.reserve(tasks.size());

    for (auto&& task : tasks) {
        futures.push_back(pool.submit(std::forward<decltype(task)>(task)));
    }

    return futures;
}

// ç­‰å¾…æ‰€æœ‰ future å®Œæˆå¹¶æ”¶é›†ç»“æœ
template <typename T>
std::vector<T> wait_all(std::vector<std::future<T>>& futures) {
    std::vector<T> results;
    results.reserve(futures.size());

    for (auto& f : futures) {
        results.push_back(f.get());
    }

    return results;
}

// ä½¿ç”¨ç¤ºä¾‹
void batch_example() {
    ThreadPoolWithFuture pool(4);

    std::vector<std::function<int()>> tasks;
    for (int i = 0; i < 10; ++i) {
        tasks.push_back([i]{ return i * i; });
    }

    auto futures = submit_batch(pool, tasks);
    auto results = wait_all(futures);

    for (int r : results) {
        std::cout << r << " ";  // 0 1 4 9 16 25 36 49 64 81
    }
}
```

**Day 3-4 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] ç†è§£ future/promise/packaged_task çš„åŒºåˆ«å’Œè”ç³»
- [ ] èƒ½æ­£ç¡®å®ç°è¿”å› future çš„ submit æ–¹æ³•
- [ ] ç†è§£å¼‚å¸¸å¦‚ä½•é€šè¿‡ future ä¼ æ’­
- [ ] èƒ½å®ç°æ‰¹é‡ä»»åŠ¡æäº¤å’Œç»“æœæ”¶é›†

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `thread_pool_with_future.hpp`
- [ ] `test_exception_propagation.cpp`
- [ ] ç¬”è®°ï¼š`notes/week1/day3-4_future_mechanism.md`

---

#### ğŸ“… Day 5-6: ä¼˜é›…å…³é—­ä¸ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆ10å°æ—¶ï¼‰

**Day 5 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- å…³é—­ç­–ç•¥åˆ†æ**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:00 | å…³é—­æ¨¡å¼ | åˆ†æä¸åŒçš„å…³é—­ç­–ç•¥ï¼šç«‹å³åœæ­¢ vs ç­‰å¾…å®Œæˆ |
| 1:00-2:00 | Javaå¯¹æ¯” | å­¦ä¹  Java ExecutorService çš„ shutdown/shutdownNow |
| 2:00-2:30 | è®¾è®¡å†³ç­– | ç¡®å®šæˆ‘ä»¬è¦æ”¯æŒçš„å…³é—­æ¨¡å¼ |

**æ ¸å¿ƒæ¦‚å¿µï¼šä¸¤ç§å…³é—­æ¨¡å¼**
```cpp
// æ¨¡å¼1ï¼šä¼˜é›…å…³é—­ï¼ˆGraceful Shutdownï¼‰
// - åœæ­¢æ¥å—æ–°ä»»åŠ¡
// - ç­‰å¾…å·²æäº¤çš„ä»»åŠ¡æ‰§è¡Œå®Œæˆ
// - ç±»ä¼¼ Java çš„ shutdown()

// æ¨¡å¼2ï¼šç«‹å³å…³é—­ï¼ˆImmediate Shutdownï¼‰
// - åœæ­¢æ¥å—æ–°ä»»åŠ¡
// - å°è¯•å–æ¶ˆæ­£åœ¨ç­‰å¾…çš„ä»»åŠ¡
// - ä¸ç­‰å¾…æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆä½†ä¸å¼ºåˆ¶ä¸­æ–­ï¼‰
// - ç±»ä¼¼ Java çš„ shutdownNow()
```

**Day 5 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- å®ç°åŒæ¨¡å¼å…³é—­**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | ä»£ç å®ç° | å®ç° shutdown å’Œ shutdown_now æ–¹æ³• |
| 2:00-2:30 | æµ‹è¯•éªŒè¯ | éªŒè¯ä¸¤ç§å…³é—­æ¨¡å¼çš„è¡Œä¸º |

**åŠ¨æ‰‹å®éªŒ 1-6ï¼šå®Œå–„çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†**
```cpp
// lifecycle_thread_pool.hpp
#pragma once
#include <thread>
#include <vector>
#include <queue>
#include <functional>
#include <future>
#include <mutex>
#include <condition_variable>
#include <atomic>

class LifecycleThreadPool {
public:
    enum class State {
        Running,      // æ­£å¸¸è¿è¡Œ
        ShuttingDown, // ä¼˜é›…å…³é—­ä¸­ï¼ˆä¸æ¥å—æ–°ä»»åŠ¡ï¼Œç­‰å¾…ç°æœ‰ä»»åŠ¡å®Œæˆï¼‰
        Stopped       // å·²åœæ­¢
    };

private:
    std::queue<std::function<void()>> tasks_;
    std::vector<std::thread> workers_;
    std::mutex mutex_;
    std::condition_variable cv_;
    std::condition_variable shutdown_cv_;  // ç”¨äºç­‰å¾…å…³é—­å®Œæˆ
    std::atomic<State> state_{State::Running};
    std::atomic<size_t> active_tasks_{0};  // æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡æ•°

    void worker_loop() {
        while (true) {
            std::function<void()> task;
            {
                std::unique_lock<std::mutex> lock(mutex_);
                cv_.wait(lock, [this] {
                    return state_ != State::Running || !tasks_.empty();
                });

                // å¦‚æœæ­£åœ¨å…³é—­ä¸”é˜Ÿåˆ—ä¸ºç©ºï¼Œé€€å‡º
                if (state_ != State::Running && tasks_.empty()) {
                    return;
                }

                // å¦‚æœæ˜¯ç«‹å³åœæ­¢ï¼Œä¹Ÿé€€å‡º
                if (state_ == State::Stopped) {
                    return;
                }

                if (!tasks_.empty()) {
                    task = std::move(tasks_.front());
                    tasks_.pop();
                    ++active_tasks_;
                }
            }

            if (task) {
                try {
                    task();
                } catch (...) {
                    // è®°å½•ä½†ä¸ä¼ æ’­
                }
                --active_tasks_;
                shutdown_cv_.notify_all();  // å¯èƒ½æœ‰äººåœ¨ç­‰å¾…å…³é—­
            }
        }
    }

public:
    explicit LifecycleThreadPool(size_t threads = std::thread::hardware_concurrency()) {
        for (size_t i = 0; i < threads; ++i) {
            workers_.emplace_back(&LifecycleThreadPool::worker_loop, this);
        }
    }

    ~LifecycleThreadPool() {
        shutdown();
        wait();
    }

    // è·å–å½“å‰çŠ¶æ€
    State state() const { return state_.load(); }

    // ä¼˜é›…å…³é—­ï¼šåœæ­¢æ¥å—æ–°ä»»åŠ¡ï¼Œç­‰å¾…ç°æœ‰ä»»åŠ¡å®Œæˆ
    void shutdown() {
        State expected = State::Running;
        if (state_.compare_exchange_strong(expected, State::ShuttingDown)) {
            cv_.notify_all();
        }
    }

    // ç«‹å³å…³é—­ï¼šæ¸…ç©ºé˜Ÿåˆ—ï¼Œä¸ç­‰å¾…
    std::vector<std::function<void()>> shutdown_now() {
        std::vector<std::function<void()>> remaining;
        {
            std::lock_guard<std::mutex> lock(mutex_);
            state_ = State::Stopped;
            while (!tasks_.empty()) {
                remaining.push_back(std::move(tasks_.front()));
                tasks_.pop();
            }
        }
        cv_.notify_all();
        return remaining;
    }

    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    void wait() {
        {
            std::unique_lock<std::mutex> lock(mutex_);
            shutdown_cv_.wait(lock, [this] {
                return tasks_.empty() && active_tasks_ == 0;
            });
        }
        for (auto& worker : workers_) {
            if (worker.joinable()) {
                worker.join();
            }
        }
    }

    // å¸¦è¶…æ—¶çš„ç­‰å¾…
    template <typename Rep, typename Period>
    bool wait_for(const std::chrono::duration<Rep, Period>& timeout) {
        std::unique_lock<std::mutex> lock(mutex_);
        return shutdown_cv_.wait_for(lock, timeout, [this] {
            return tasks_.empty() && active_tasks_ == 0;
        });
    }

    // æäº¤ä»»åŠ¡
    template <typename F, typename... Args>
    auto submit(F&& f, Args&&... args)
        -> std::future<std::invoke_result_t<F, Args...>>
    {
        using ReturnType = std::invoke_result_t<F, Args...>;

        if (state_ != State::Running) {
            throw std::runtime_error("ThreadPool is not running");
        }

        auto task = std::make_shared<std::packaged_task<ReturnType()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...)
        );

        std::future<ReturnType> result = task->get_future();

        {
            std::lock_guard<std::mutex> lock(mutex_);
            if (state_ != State::Running) {
                throw std::runtime_error("ThreadPool is not running");
            }
            tasks_.emplace([task]() { (*task)(); });
        }
        cv_.notify_one();

        return result;
    }

    // æŸ¥è¯¢ä¿¡æ¯
    size_t pending_tasks() const {
        std::lock_guard<std::mutex> lock(const_cast<std::mutex&>(mutex_));
        return tasks_.size();
    }

    size_t active_tasks() const {
        return active_tasks_.load();
    }

    size_t thread_count() const {
        return workers_.size();
    }
};
```

**Day 6 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- çº¿ç¨‹æ± çŠ¶æ€æœº**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | çŠ¶æ€æœºè®¾è®¡ | ç»˜åˆ¶å®Œæ•´çš„çŠ¶æ€è½¬æ¢å›¾ |
| 1:30-2:30 | è¾¹ç•Œæµ‹è¯• | æµ‹è¯•å„ç§çŠ¶æ€è½¬æ¢åœºæ™¯ |

**çŠ¶æ€è½¬æ¢å›¾**ï¼š
```
                 submit()
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                              â”‚
    â–¼                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  shutdown()   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  tasks done   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Running â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ ShuttingDown  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Stopped â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                                                          â–²
    â”‚                    shutdown_now()                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Day 6 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- ç»¼åˆæµ‹è¯•**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | å‹åŠ›æµ‹è¯• | ç¼–å†™å¤šåœºæ™¯çš„å‹åŠ›æµ‹è¯• |
| 2:00-2:30 | é—®é¢˜ä¿®å¤ | ä¿®å¤å‘ç°çš„é—®é¢˜ |

**åŠ¨æ‰‹å®éªŒ 1-7ï¼šç”Ÿå‘½å‘¨æœŸæµ‹è¯•**
```cpp
// test_lifecycle.cpp
#include "lifecycle_thread_pool.hpp"
#include <iostream>
#include <chrono>

void test_graceful_shutdown() {
    std::cout << "=== Test Graceful Shutdown ===\n";
    LifecycleThreadPool pool(4);

    std::atomic<int> completed{0};

    // æäº¤ä¸€äº›è€—æ—¶ä»»åŠ¡
    for (int i = 0; i < 10; ++i) {
        pool.submit([&completed, i] {
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
            ++completed;
            std::cout << "Task " << i << " completed\n";
        });
    }

    std::cout << "Initiating shutdown...\n";
    pool.shutdown();

    // å°è¯•æäº¤æ–°ä»»åŠ¡åº”è¯¥å¤±è´¥
    try {
        pool.submit([] { std::cout << "This should not run\n"; });
    } catch (const std::exception& e) {
        std::cout << "Expected error: " << e.what() << "\n";
    }

    pool.wait();
    std::cout << "Completed tasks: " << completed << "/10\n";
}

void test_immediate_shutdown() {
    std::cout << "\n=== Test Immediate Shutdown ===\n";
    LifecycleThreadPool pool(2);

    // æäº¤å¾ˆå¤šä»»åŠ¡
    for (int i = 0; i < 100; ++i) {
        pool.submit([i] {
            std::this_thread::sleep_for(std::chrono::milliseconds(50));
        });
    }

    std::this_thread::sleep_for(std::chrono::milliseconds(100));

    auto remaining = pool.shutdown_now();
    std::cout << "Cancelled " << remaining.size() << " pending tasks\n";
}

int main() {
    test_graceful_shutdown();
    test_immediate_shutdown();
    return 0;
}
```

**Day 5-6 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] ç†è§£ä¼˜é›…å…³é—­å’Œç«‹å³å…³é—­çš„åŒºåˆ«
- [ ] æ­£ç¡®å®ç°çŠ¶æ€æœºè½¬æ¢
- [ ] èƒ½å¤„ç†å…³é—­è¿‡ç¨‹ä¸­çš„å¹¶å‘æäº¤
- [ ] å®ç°å¸¦è¶…æ—¶çš„ç­‰å¾…

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `lifecycle_thread_pool.hpp`
- [ ] `test_lifecycle.cpp`
- [ ] ç¬”è®°ï¼š`notes/week1/day5-6_lifecycle.md`

---

#### ğŸ“… Day 7: ç¬¬ä¸€å‘¨æ€»ç»“ä¸æ‰©å±•é˜…è¯»ï¼ˆ5å°æ—¶ï¼‰

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | æºç é˜…è¯» | é˜…è¯» Boost.Asio çº¿ç¨‹æ± å®ç° |
| 2:00-3:00 | å¯¹æ¯”åˆ†æ | å¯¹æ¯”æˆ‘ä»¬çš„å®ç°ä¸ std::async |
| 3:00-4:00 | ç¬”è®°æ•´ç† | æ•´ç†æœ¬å‘¨å­¦ä¹ ç¬”è®° |
| 4:00-5:00 | é¢„ä¹ å‡†å¤‡ | é¢„ä¹ ä¸‹å‘¨å·¥ä½œçªƒå–ä¸»é¢˜ |

**æ‰©å±•é˜…è¯»**ï¼š
- [ ] Boost.Asio thread_pool æºç 
- [ ] folly::ThreadPoolExecutor è®¾è®¡æ–‡æ¡£
- [ ] Intel TBB task_arena ä»‹ç»

**ç¬¬ä¸€å‘¨è¾“å‡ºç‰©æ±‡æ€»**ï¼š
1. `thread_safe_queue.hpp` - çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—
2. `basic_thread_pool.hpp` - åŸºç¡€çº¿ç¨‹æ± 
3. `thread_pool_with_future.hpp` - æ”¯æŒè¿”å›å€¼çš„çº¿ç¨‹æ± 
4. `lifecycle_thread_pool.hpp` - å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†
5. `test_*.cpp` - æµ‹è¯•æ–‡ä»¶
6. `notes/week1/` - æœ¬å‘¨ç¬”è®°

---

### ç¬¬äºŒå‘¨ï¼šå·¥ä½œçªƒå–ï¼ˆWork Stealingï¼‰

**å­¦ä¹ ç›®æ ‡**ï¼šæ·±å…¥ç†è§£å·¥ä½œçªƒå–ç®—æ³•ï¼Œå®ç°é«˜æ•ˆçš„è´Ÿè½½å‡è¡¡çº¿ç¨‹æ± 

**é˜…è¯»ææ–™**ï¼š
- [ ] è®ºæ–‡ï¼šBlumofe & Leiserson "Scheduling Multithreaded Computations by Work Stealing"
- [ ] è®ºæ–‡ï¼šChase & Lev "Dynamic Circular Work-Stealing Deque"
- [ ] CppCon 2018: "C++ Executors: The Good, The Bad, and Some Examples"
- [ ] Java Fork/Join Framework æ–‡æ¡£

---

#### ğŸ“… Day 1-2: å·¥ä½œçªƒå–åŸç†ï¼ˆ10å°æ—¶ï¼‰

**Day 1 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- ä¸ºä»€ä¹ˆéœ€è¦å·¥ä½œçªƒå–ï¼Ÿ**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:00 | ä¼ ç»Ÿçº¿ç¨‹æ± é—®é¢˜ | åˆ†æå•ä¸€ä»»åŠ¡é˜Ÿåˆ—çš„ç“¶é¢ˆï¼šé”ç«äº‰ã€è´Ÿè½½ä¸å‡ |
| 1:00-2:00 | å·¥ä½œçªƒå–æ€æƒ³ | ç†è§£"æ¯ä¸ªçº¿ç¨‹æœ‰æœ¬åœ°é˜Ÿåˆ—ï¼Œç©ºé—²æ—¶çªƒå–"çš„è®¾è®¡ |
| 2:00-2:30 | å›¾è§£ç†è§£ | ç”»å‡ºå·¥ä½œçªƒå–çš„æ•°æ®æµå›¾ |

**æ ¸å¿ƒæ¦‚å¿µï¼šä¼ ç»Ÿçº¿ç¨‹æ±  vs å·¥ä½œçªƒå–**
```
ä¼ ç»Ÿçº¿ç¨‹æ± ï¼ˆå•ä¸€é˜Ÿåˆ—ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Global Task Queue           â”‚  <-- æ‰€æœ‰çº¿ç¨‹ç«äº‰åŒä¸€æŠŠé”
â”‚    [T1] [T2] [T3] [T4] [T5] ...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ é«˜ç«äº‰ï¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Worker 1â”‚ â”‚Worker 2â”‚ â”‚Worker 3â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å·¥ä½œçªƒå–çº¿ç¨‹æ± ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker 1          Worker 2          Worker 3          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚Local Q â”‚        â”‚Local Q â”‚        â”‚Local Q â”‚       â”‚
â”‚  â”‚[T1][T2]â”‚        â”‚[T3]    â”‚        â”‚        â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚      â”‚                                    â”‚           â”‚
â”‚      â”‚              steal â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚      â–¼                                                â”‚
â”‚  æ‰§è¡Œ T1                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Day 1 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- åŒç«¯é˜Ÿåˆ—çš„å¿…è¦æ€§**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:00 | ä¸ºä»€ä¹ˆç”¨ Deque | ç†è§£ LIFO æœ¬åœ°è®¿é—® + FIFO çªƒå–çš„ä¼˜åŠ¿ |
| 1:00-2:00 | ç¼“å­˜å±€éƒ¨æ€§ | åˆ†æä¸ºä»€ä¹ˆä»é˜Ÿå°¾çªƒå–èƒ½æé«˜ç¼“å­˜å‘½ä¸­ç‡ |
| 2:00-2:30 | æ•°æ®ç»“æ„é€‰æ‹© | å¯¹æ¯”å„ç§å¹¶å‘é˜Ÿåˆ—çš„é€‚ç”¨åœºæ™¯ |

**æ ¸å¿ƒæ¦‚å¿µï¼šDeque çš„è®¿é—®æ¨¡å¼**
```cpp
/*
å·¥ä½œçªƒå– Deque çš„è®¿é—®æ¨¡å¼ï¼š

æ‰€æœ‰è€…çº¿ç¨‹ï¼ˆOwnerï¼‰ï¼š
- push: ä» bottom ç«¯æ·»åŠ ï¼ˆæ–°ä»»åŠ¡ï¼‰
- pop:  ä» bottom ç«¯å–å‡ºï¼ˆæœ€è¿‘æ·»åŠ çš„ä»»åŠ¡ï¼ŒLIFOï¼‰

çªƒå–è€…çº¿ç¨‹ï¼ˆThiefï¼‰ï¼š
- steal: ä» top ç«¯å–å‡ºï¼ˆæœ€æ—©æ·»åŠ çš„ä»»åŠ¡ï¼ŒFIFOï¼‰

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   top                           â”‚  <-- çªƒå–è€…ä»è¿™é‡Œå–ï¼ˆFIFOï¼‰
â”‚   â†“                             â”‚
â”‚   [Task A] [Task B] [Task C]    â”‚
â”‚                           â†‘     â”‚
â”‚                         bottom  â”‚  <-- æ‰€æœ‰è€…åœ¨è¿™é‡Œæ“ä½œï¼ˆLIFOï¼‰
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ
1. ç¼“å­˜å±€éƒ¨æ€§ï¼šæ‰€æœ‰è€…æ‰§è¡Œæœ€è¿‘æ·»åŠ çš„ä»»åŠ¡ï¼Œæ•°æ®æ›´å¯èƒ½åœ¨ç¼“å­˜ä¸­
2. å‡å°‘ç«äº‰ï¼šæ‰€æœ‰è€…å’Œçªƒå–è€…åœ¨ä¸åŒç«¯æ“ä½œï¼Œå¤§å¤šæ•°æƒ…å†µæ— ç«äº‰
3. ä»»åŠ¡ç²’åº¦ï¼šçªƒå–çš„æ˜¯è¾ƒæ—©ï¼ˆé€šå¸¸è¾ƒå¤§ï¼‰çš„ä»»åŠ¡ï¼Œå‡å°‘çªƒå–é¢‘ç‡
*/
```

**Day 2 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- Chase-Lev Deque è®ºæ–‡ç²¾è¯»**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | è®ºæ–‡é˜…è¯» | ç²¾è¯» "Dynamic Circular Work-Stealing Deque" |
| 1:30-2:30 | ç®—æ³•ç†è§£ | ç”»å‡º push/pop/steal çš„çŠ¶æ€è½¬æ¢å›¾ |

**Day 2 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- ç®€åŒ–ç‰ˆå·¥ä½œçªƒå–é˜Ÿåˆ—**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | åŸºç¡€å®ç° | å®ç°å¸¦é”çš„ç®€åŒ–ç‰ˆå·¥ä½œçªƒå–é˜Ÿåˆ— |
| 2:00-2:30 | æµ‹è¯•éªŒè¯ | éªŒè¯æ­£ç¡®æ€§ |

**åŠ¨æ‰‹å®éªŒ 2-1ï¼šç®€åŒ–ç‰ˆå·¥ä½œçªƒå–é˜Ÿåˆ—ï¼ˆå¸¦é”ï¼‰**
```cpp
// simple_ws_deque.hpp
#pragma once
#include <deque>
#include <mutex>
#include <optional>

template <typename T>
class SimpleWSDeque {
    std::deque<T> deque_;
    mutable std::mutex mutex_;

public:
    // æ‰€æœ‰è€…ï¼šä» bottom æ·»åŠ 
    void push(T item) {
        std::lock_guard<std::mutex> lock(mutex_);
        deque_.push_back(std::move(item));
    }

    // æ‰€æœ‰è€…ï¼šä» bottom å–å‡ºï¼ˆLIFOï¼‰
    std::optional<T> pop() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (deque_.empty()) {
            return std::nullopt;
        }
        T item = std::move(deque_.back());
        deque_.pop_back();
        return item;
    }

    // çªƒå–è€…ï¼šä» top å–å‡ºï¼ˆFIFOï¼‰
    std::optional<T> steal() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (deque_.empty()) {
            return std::nullopt;
        }
        T item = std::move(deque_.front());
        deque_.pop_front();
        return item;
    }

    bool empty() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return deque_.empty();
    }

    size_t size() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return deque_.size();
    }
};
```

**Day 1-2 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] èƒ½è§£é‡Šå·¥ä½œçªƒå–ç›¸æ¯”ä¼ ç»Ÿçº¿ç¨‹æ± çš„ä¼˜åŠ¿
- [ ] ç†è§£ä¸ºä»€ä¹ˆä½¿ç”¨ Deque è€Œä¸æ˜¯æ™®é€šé˜Ÿåˆ—
- [ ] ç†è§£ LIFO æœ¬åœ°è®¿é—®å’Œ FIFO çªƒå–çš„åŸå› 
- [ ] å®ç°ç®€åŒ–ç‰ˆå·¥ä½œçªƒå–é˜Ÿåˆ—

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `simple_ws_deque.hpp`
- [ ] ç¬”è®°ï¼š`notes/week2/day1-2_work_stealing_theory.md`

---

#### ğŸ“… Day 3-4: æ— é”å·¥ä½œçªƒå–é˜Ÿåˆ—ï¼ˆ10å°æ—¶ï¼‰

**Day 3 ä¸Šåˆï¼ˆ2.5å°æ—¶ï¼‰- Chase-Lev Deque ç®—æ³•è¯¦è§£**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | ç®—æ³•åˆ†æ | é€è¡Œç†è§£ Chase-Lev ç®—æ³•çš„æ¯ä¸ªæ“ä½œ |
| 1:30-2:30 | å†…å­˜åºåˆ†æ | åˆ†ææ¯ä¸ªåŸå­æ“ä½œéœ€è¦çš„å†…å­˜åº |

**æ ¸å¿ƒæ¦‚å¿µï¼šChase-Lev Deque ç®—æ³•**
```cpp
/*
Chase-Lev Work-Stealing Deque æ ¸å¿ƒæ€æƒ³ï¼š

æ•°æ®ç»“æ„ï¼š
- ç¯å½¢æ•°ç»„ buffer[]
- top: çªƒå–ç«¯ç´¢å¼•ï¼ˆåŸå­å˜é‡ï¼‰
- bottom: æ‰€æœ‰è€…ç«¯ç´¢å¼•ï¼ˆåŸå­å˜é‡ï¼‰

å…³é”®ä¸å˜é‡ï¼š
- top <= bottomï¼ˆå§‹ç»ˆæˆç«‹ï¼‰
- æœ‰æ•ˆå…ƒç´ åœ¨ [top, bottom) èŒƒå›´å†…
- size = bottom - top

æ“ä½œå¤æ‚åº¦ï¼š
- push:  O(1)ï¼Œæ— ç«äº‰
- pop:   O(1)ï¼Œå¯èƒ½ä¸ steal ç«äº‰
- steal: O(1)ï¼Œå¯èƒ½ä¸ pop æˆ–å…¶ä»– steal ç«äº‰

ç«äº‰æƒ…å†µåˆ†æï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜Ÿåˆ—çŠ¶æ€     â”‚ push         â”‚ pop          â”‚ steal        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¤šä¸ªå…ƒç´      â”‚ æ— ç«äº‰       â”‚ æ— ç«äº‰       â”‚ å¯èƒ½ç«äº‰stealâ”‚
â”‚ å•ä¸ªå…ƒç´      â”‚ æ— ç«äº‰       â”‚ ä¸stealç«äº‰  â”‚ ä¸popç«äº‰    â”‚
â”‚ ç©º           â”‚ æ— ç«äº‰       â”‚ æ— ç«äº‰       â”‚ æ— ç«äº‰       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
*/
```

**Day 3 ä¸‹åˆï¼ˆ2.5å°æ—¶ï¼‰- å®ç°æ— é” Deque**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | æ ¸å¿ƒå®ç° | å®ç° pushã€popã€steal æ“ä½œ |
| 2:00-2:30 | åˆæ­¥æµ‹è¯• | å•çº¿ç¨‹æ­£ç¡®æ€§æµ‹è¯• |

**åŠ¨æ‰‹å®éªŒ 2-2ï¼šChase-Lev æ— é” Deque**
```cpp
// chase_lev_deque.hpp
#pragma once
#include <atomic>
#include <vector>
#include <memory>
#include <optional>
#include <cassert>

template <typename T>
class ChaseLevDeque {
    struct CircularArray {
        std::vector<T> buffer;
        size_t mask;

        explicit CircularArray(size_t capacity)
            : buffer(capacity), mask(capacity - 1) {
            assert((capacity & (capacity - 1)) == 0);
        }

        size_t capacity() const { return buffer.size(); }

        T& operator[](size_t index) {
            return buffer[index & mask];
        }

        std::unique_ptr<CircularArray> grow(size_t top, size_t bottom) {
            auto new_array = std::make_unique<CircularArray>(capacity() * 2);
            for (size_t i = top; i < bottom; ++i) {
                (*new_array)[i] = std::move((*this)[i]);
            }
            return new_array;
        }
    };

    std::atomic<size_t> top_{0};
    std::atomic<size_t> bottom_{0};
    std::atomic<CircularArray*> array_;
    std::vector<std::unique_ptr<CircularArray>> old_arrays_;
    std::mutex old_arrays_mutex_;

public:
    explicit ChaseLevDeque(size_t initial_capacity = 32) {
        size_t capacity = 1;
        while (capacity < initial_capacity) capacity *= 2;
        array_.store(new CircularArray(capacity));
    }

    ~ChaseLevDeque() { delete array_.load(); }

    void push(T item) {
        size_t b = bottom_.load(std::memory_order_relaxed);
        size_t t = top_.load(std::memory_order_acquire);
        CircularArray* arr = array_.load(std::memory_order_relaxed);

        if (b - t >= arr->capacity() - 1) {
            auto new_arr = arr->grow(t, b);
            {
                std::lock_guard<std::mutex> lock(old_arrays_mutex_);
                old_arrays_.push_back(std::unique_ptr<CircularArray>(arr));
            }
            arr = new_arr.release();
            array_.store(arr, std::memory_order_release);
        }

        (*arr)[b] = std::move(item);
        std::atomic_thread_fence(std::memory_order_release);
        bottom_.store(b + 1, std::memory_order_relaxed);
    }

    std::optional<T> pop() {
        size_t b = bottom_.load(std::memory_order_relaxed) - 1;
        CircularArray* arr = array_.load(std::memory_order_relaxed);
        bottom_.store(b, std::memory_order_relaxed);
        std::atomic_thread_fence(std::memory_order_seq_cst);
        size_t t = top_.load(std::memory_order_relaxed);

        if (t <= b) {
            T item = std::move((*arr)[b]);
            if (t == b) {
                if (!top_.compare_exchange_strong(t, t + 1,
                        std::memory_order_seq_cst, std::memory_order_relaxed)) {
                    bottom_.store(b + 1, std::memory_order_relaxed);
                    return std::nullopt;
                }
                bottom_.store(b + 1, std::memory_order_relaxed);
            }
            return item;
        } else {
            bottom_.store(b + 1, std::memory_order_relaxed);
            return std::nullopt;
        }
    }

    std::optional<T> steal() {
        size_t t = top_.load(std::memory_order_acquire);
        std::atomic_thread_fence(std::memory_order_seq_cst);
        size_t b = bottom_.load(std::memory_order_acquire);

        if (t < b) {
            CircularArray* arr = array_.load(std::memory_order_consume);
            T item = (*arr)[t];
            if (!top_.compare_exchange_strong(t, t + 1,
                    std::memory_order_seq_cst, std::memory_order_relaxed)) {
                return std::nullopt;
            }
            return item;
        }
        return std::nullopt;
    }

    bool empty() const {
        return top_.load(std::memory_order_relaxed) >=
               bottom_.load(std::memory_order_relaxed);
    }
};
```

**Day 4ï¼ˆ5å°æ—¶ï¼‰- æµ‹è¯•ä¸æ€§èƒ½åˆ†æ**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | å¤šçº¿ç¨‹æµ‹è¯• | ç¼–å†™å¹¶å‘æµ‹è¯•ï¼ŒéªŒè¯æ­£ç¡®æ€§ |
| 2:00-3:30 | TSan æ£€æµ‹ | ä½¿ç”¨ ThreadSanitizer æ£€æµ‹æ•°æ®ç«äº‰ |
| 3:30-5:00 | æ€§èƒ½æµ‹è¯• | å¯¹æ¯”æœ‰é”å’Œæ— é”ç‰ˆæœ¬ |

**Day 3-4 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] ç†è§£ Chase-Lev ç®—æ³•çš„æ¯ä¸ªæ“ä½œ
- [ ] æ­£ç¡®åˆ†æå†…å­˜åºçš„é€‰æ‹©
- [ ] å®ç°é€šè¿‡å¤šçº¿ç¨‹æ­£ç¡®æ€§æµ‹è¯•

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `chase_lev_deque.hpp`
- [ ] `test_chase_lev.cpp`
- [ ] ç¬”è®°ï¼š`notes/week2/day3-4_lock_free_deque.md`

---

#### ğŸ“… Day 5-6: Fork/Join æ¨¡å¼ä¸å·¥ä½œçªƒå–çº¿ç¨‹æ± ï¼ˆ10å°æ—¶ï¼‰

**Day 5ï¼ˆ5å°æ—¶ï¼‰- å·¥ä½œçªƒå–çº¿ç¨‹æ± å®ç°**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:00 | Fork/Join æ¦‚å¿µ | ç†è§£åˆ†æ²»å¹¶è¡Œçš„æ ¸å¿ƒæ€æƒ³ |
| 1:00-2:30 | çº¿ç¨‹æ± å®ç° | æ•´åˆ Chase-Lev Deque å®ç°çº¿ç¨‹æ±  |
| 2:30-5:00 | æµ‹è¯•éªŒè¯ | éªŒè¯åŸºæœ¬åŠŸèƒ½ |

**åŠ¨æ‰‹å®éªŒ 2-4ï¼šå·¥ä½œçªƒå–çº¿ç¨‹æ± **
```cpp
// work_stealing_pool.hpp
#pragma once
#include <thread>
#include <vector>
#include <functional>
#include <future>
#include <atomic>
#include <random>
#include "chase_lev_deque.hpp"

class WorkStealingPool {
    using Task = std::function<void()>;

    std::vector<std::unique_ptr<ChaseLevDeque<Task>>> local_queues_;
    std::vector<std::thread> workers_;
    std::atomic<bool> running_{true};
    static thread_local size_t worker_id_;

    void worker_loop(size_t id) {
        worker_id_ = id;
        std::mt19937 rng(id);

        while (running_) {
            Task task;
            auto local_task = local_queues_[id]->pop();
            if (local_task) {
                task = std::move(*local_task);
            } else {
                // å°è¯•çªƒå–
                size_t n = local_queues_.size();
                size_t start = rng() % n;
                for (size_t i = 0; i < n; ++i) {
                    size_t victim = (start + i) % n;
                    if (victim == id) continue;
                    auto stolen = local_queues_[victim]->steal();
                    if (stolen) {
                        task = std::move(*stolen);
                        break;
                    }
                }
            }

            if (task) {
                try { task(); } catch (...) {}
            } else {
                std::this_thread::yield();
            }
        }
    }

public:
    explicit WorkStealingPool(size_t threads = std::thread::hardware_concurrency()) {
        for (size_t i = 0; i < threads; ++i) {
            local_queues_.push_back(std::make_unique<ChaseLevDeque<Task>>());
        }
        for (size_t i = 0; i < threads; ++i) {
            workers_.emplace_back(&WorkStealingPool::worker_loop, this, i);
        }
    }

    ~WorkStealingPool() {
        running_ = false;
        for (auto& w : workers_) if (w.joinable()) w.join();
    }

    template <typename F, typename... Args>
    auto submit(F&& f, Args&&... args)
        -> std::future<std::invoke_result_t<F, Args...>>
    {
        using R = std::invoke_result_t<F, Args...>;
        auto task = std::make_shared<std::packaged_task<R()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        std::future<R> result = task->get_future();

        size_t target = (worker_id_ < workers_.size()) ? worker_id_ :
            (std::hash<std::thread::id>{}(std::this_thread::get_id()) % workers_.size());
        local_queues_[target]->push([task]() { (*task)(); });
        return result;
    }
};

thread_local size_t WorkStealingPool::worker_id_ = SIZE_MAX;
```

**Day 6ï¼ˆ5å°æ—¶ï¼‰- Fork/Join ä»»åŠ¡ä¸æ€§èƒ½å¯¹æ¯”**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:30 | Fork/Join å®ç° | å®ç°å¹¶è¡Œæ±‚å’Œç­‰é€’å½’ä»»åŠ¡ |
| 2:30-5:00 | æ€§èƒ½å¯¹æ¯” | å¯¹æ¯”å·¥ä½œçªƒå–ä¸ä¼ ç»Ÿçº¿ç¨‹æ±  |

**Day 5-6 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] ç†è§£ Fork/Join æ¨¡å¼çš„æ ¸å¿ƒæ€æƒ³
- [ ] å®ç°å·¥ä½œçªƒå–çº¿ç¨‹æ± 
- [ ] å¯¹æ¯”åˆ†æå·¥ä½œçªƒå–çš„æ€§èƒ½ä¼˜åŠ¿

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `work_stealing_pool.hpp`
- [ ] `benchmark_work_stealing.cpp`
- [ ] ç¬”è®°ï¼š`notes/week2/day5-6_fork_join.md`

---

#### ğŸ“… Day 7: ç¬¬äºŒå‘¨æ€»ç»“ï¼ˆ5å°æ—¶ï¼‰

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | æºç é˜…è¯» | é˜…è¯» Intel TBB çš„ task_arena å®ç° |
| 2:00-4:00 | å¯¹æ¯”åˆ†æ | å¯¹æ¯” Java ForkJoinPoolã€Tokioã€Go runtime |
| 4:00-5:00 | ç¬”è®°æ•´ç† | æ•´ç†æœ¬å‘¨å­¦ä¹ ç¬”è®° |

**ç¬¬äºŒå‘¨è¾“å‡ºç‰©æ±‡æ€»**ï¼š
1. `simple_ws_deque.hpp` - ç®€åŒ–ç‰ˆå·¥ä½œçªƒå–é˜Ÿåˆ—
2. `chase_lev_deque.hpp` - æ— é” Chase-Lev Deque
3. `work_stealing_pool.hpp` - å·¥ä½œçªƒå–çº¿ç¨‹æ± 
4. `test_*.cpp` / `benchmark_*.cpp` - æµ‹è¯•å’ŒåŸºå‡†æ–‡ä»¶
5. `notes/week2/` - æœ¬å‘¨ç¬”è®°

---

### ç¬¬ä¸‰å‘¨ï¼šä»»åŠ¡ä¼˜å…ˆçº§ä¸ä¾èµ–

**å­¦ä¹ ç›®æ ‡**ï¼šå®ç°æ”¯æŒä¼˜å…ˆçº§è°ƒåº¦å’Œä»»åŠ¡ä¾èµ–çš„çº¿ç¨‹æ± 

**é˜…è¯»ææ–™**ï¼š
- [ ] ã€Šç®—æ³•å¯¼è®ºã€‹å›¾ç®—æ³•ç« èŠ‚ï¼ˆæ‹“æ‰‘æ’åºï¼‰
- [ ] Java ScheduledThreadPoolExecutor æºç åˆ†æ
- [ ] åšå®¢ï¼šHashed and Hierarchical Timing Wheels

---

#### ğŸ“… Day 1-2: ä¼˜å…ˆçº§é˜Ÿåˆ—ä¸ä»»åŠ¡è°ƒåº¦ï¼ˆ10å°æ—¶ï¼‰

**Day 1ï¼ˆ5å°æ—¶ï¼‰- ä¼˜å…ˆçº§è°ƒåº¦ç­–ç•¥**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | è°ƒåº¦ç­–ç•¥åˆ†æ | å­¦ä¹  FIFOã€ä¼˜å…ˆçº§ã€å…¬å¹³è°ƒåº¦ç­‰ç­–ç•¥ |
| 1:30-3:00 | ä¼˜å…ˆçº§é˜Ÿåˆ— | ä½¿ç”¨ std::priority_queue å®ç°ä¼˜å…ˆçº§è°ƒåº¦ |
| 3:00-5:00 | ä»£ç å®ç° | å®ç°æ”¯æŒä¼˜å…ˆçº§çš„çº¿ç¨‹æ±  |

**æ ¸å¿ƒæ¦‚å¿µï¼šå¸¸è§è°ƒåº¦ç­–ç•¥**
```cpp
/*
è°ƒåº¦ç­–ç•¥å¯¹æ¯”ï¼š

1. FIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰
   - ç®€å•å…¬å¹³
   - æ— æ³•å¤„ç†ç´§æ€¥ä»»åŠ¡
   - é€‚ç”¨ï¼šå¤§å¤šæ•°é€šç”¨åœºæ™¯

2. ä¼˜å…ˆçº§è°ƒåº¦
   - é«˜ä¼˜å…ˆçº§ä»»åŠ¡ä¼˜å…ˆæ‰§è¡Œ
   - å¯èƒ½å¯¼è‡´ä½ä¼˜å…ˆçº§ä»»åŠ¡é¥¥é¥¿
   - é€‚ç”¨ï¼šå®æ—¶ç³»ç»Ÿã€ç´§æ€¥ä»»åŠ¡å¤„ç†

3. å…¬å¹³è°ƒåº¦ï¼ˆFair Shareï¼‰
   - æŒ‰æ¯”ä¾‹åˆ†é…æ‰§è¡Œæ—¶é—´
   - é¿å…é¥¥é¥¿
   - é€‚ç”¨ï¼šå¤šç§Ÿæˆ·ç³»ç»Ÿ

4. å·¥ä½œçªƒå– + ä¼˜å…ˆçº§
   - æœ¬åœ°é˜Ÿåˆ—å†…æŒ‰ä¼˜å…ˆçº§
   - çªƒå–æ—¶ä¼˜å…ˆé€‰æ‹©é«˜ä¼˜å…ˆçº§ä»»åŠ¡
   - é€‚ç”¨ï¼šå¤æ‚å¹¶è¡Œè®¡ç®—
*/
```

**åŠ¨æ‰‹å®éªŒ 3-1ï¼šä¼˜å…ˆçº§çº¿ç¨‹æ± **
```cpp
// priority_thread_pool.hpp
#pragma once
#include <thread>
#include <vector>
#include <queue>
#include <functional>
#include <future>
#include <mutex>
#include <condition_variable>

class PriorityThreadPool {
public:
    enum class Priority { Low = 0, Normal = 1, High = 2, Critical = 3 };

private:
    struct PriorityTask {
        Priority priority;
        uint64_t sequence;  // ç”¨äºåœ¨ç›¸åŒä¼˜å…ˆçº§æ—¶ä¿æŒ FIFO
        std::function<void()> task;

        bool operator<(const PriorityTask& other) const {
            // priority_queue æ˜¯æœ€å¤§å †ï¼Œæˆ‘ä»¬æƒ³è¦é«˜ä¼˜å…ˆçº§å…ˆå‡º
            if (priority != other.priority) {
                return priority < other.priority;
            }
            // ç›¸åŒä¼˜å…ˆçº§ï¼Œå…ˆæäº¤çš„å…ˆæ‰§è¡Œ
            return sequence > other.sequence;
        }
    };

    std::priority_queue<PriorityTask> tasks_;
    std::vector<std::thread> workers_;
    std::mutex mutex_;
    std::condition_variable cv_;
    std::atomic<bool> stop_{false};
    std::atomic<uint64_t> sequence_{0};

    void worker_loop() {
        while (true) {
            std::function<void()> task;
            {
                std::unique_lock<std::mutex> lock(mutex_);
                cv_.wait(lock, [this] { return stop_ || !tasks_.empty(); });

                if (stop_ && tasks_.empty()) return;

                task = std::move(const_cast<PriorityTask&>(tasks_.top()).task);
                tasks_.pop();
            }
            if (task) {
                try { task(); } catch (...) {}
            }
        }
    }

public:
    explicit PriorityThreadPool(size_t threads = std::thread::hardware_concurrency()) {
        for (size_t i = 0; i < threads; ++i) {
            workers_.emplace_back(&PriorityThreadPool::worker_loop, this);
        }
    }

    ~PriorityThreadPool() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            stop_ = true;
        }
        cv_.notify_all();
        for (auto& w : workers_) if (w.joinable()) w.join();
    }

    template <typename F, typename... Args>
    auto submit(Priority priority, F&& f, Args&&... args)
        -> std::future<std::invoke_result_t<F, Args...>>
    {
        using R = std::invoke_result_t<F, Args...>;
        auto task = std::make_shared<std::packaged_task<R()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        std::future<R> result = task->get_future();

        {
            std::lock_guard<std::mutex> lock(mutex_);
            tasks_.push(PriorityTask{
                priority,
                sequence_++,
                [task]() { (*task)(); }
            });
        }
        cv_.notify_one();
        return result;
    }

    // ä¾¿æ·æ–¹æ³•
    template <typename F, typename... Args>
    auto submit(F&& f, Args&&... args) {
        return submit(Priority::Normal,
                      std::forward<F>(f), std::forward<Args>(args)...);
    }
};
```

**Day 2ï¼ˆ5å°æ—¶ï¼‰- é˜²æ­¢ä¼˜å…ˆçº§åè½¬ä¸é¥¥é¥¿**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | ä¼˜å…ˆçº§åè½¬ | ç†è§£ä¼˜å…ˆçº§åè½¬é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ |
| 2:00-3:30 | è€åŒ–æœºåˆ¶ | å®ç°ä»»åŠ¡è€åŒ–é˜²æ­¢é¥¥é¥¿ |
| 3:30-5:00 | æµ‹è¯•éªŒè¯ | éªŒè¯é˜²é¥¥é¥¿æœºåˆ¶ |

**åŠ¨æ‰‹å®éªŒ 3-2ï¼šå¸¦è€åŒ–æœºåˆ¶çš„ä¼˜å…ˆçº§é˜Ÿåˆ—**
```cpp
// aging_priority_queue.hpp
#pragma once
#include <chrono>
#include <queue>
#include <mutex>

template <typename T>
class AgingPriorityQueue {
    struct Entry {
        T item;
        int base_priority;
        std::chrono::steady_clock::time_point submit_time;

        // è®¡ç®—æœ‰æ•ˆä¼˜å…ˆçº§ï¼ˆè€ƒè™‘è€åŒ–ï¼‰
        int effective_priority(std::chrono::steady_clock::time_point now) const {
            auto age = std::chrono::duration_cast<std::chrono::seconds>(
                now - submit_time).count();
            // æ¯ç­‰å¾…10ç§’ï¼Œä¼˜å…ˆçº§æå‡1
            return base_priority + static_cast<int>(age / 10);
        }
    };

    std::vector<Entry> heap_;
    mutable std::mutex mutex_;

    void heapify_up(size_t index) {
        auto now = std::chrono::steady_clock::now();
        while (index > 0) {
            size_t parent = (index - 1) / 2;
            if (heap_[index].effective_priority(now) <=
                heap_[parent].effective_priority(now)) {
                break;
            }
            std::swap(heap_[index], heap_[parent]);
            index = parent;
        }
    }

    void heapify_down(size_t index) {
        auto now = std::chrono::steady_clock::now();
        size_t size = heap_.size();
        while (true) {
            size_t largest = index;
            size_t left = 2 * index + 1;
            size_t right = 2 * index + 2;

            if (left < size &&
                heap_[left].effective_priority(now) >
                heap_[largest].effective_priority(now)) {
                largest = left;
            }
            if (right < size &&
                heap_[right].effective_priority(now) >
                heap_[largest].effective_priority(now)) {
                largest = right;
            }

            if (largest == index) break;
            std::swap(heap_[index], heap_[largest]);
            index = largest;
        }
    }

public:
    void push(T item, int priority) {
        std::lock_guard<std::mutex> lock(mutex_);
        heap_.push_back(Entry{
            std::move(item),
            priority,
            std::chrono::steady_clock::now()
        });
        heapify_up(heap_.size() - 1);
    }

    std::optional<T> pop() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (heap_.empty()) return std::nullopt;

        // é‡æ–°å †åŒ–ï¼ˆè€ƒè™‘è€åŒ–ï¼‰
        auto now = std::chrono::steady_clock::now();
        for (size_t i = heap_.size() / 2; i > 0; --i) {
            heapify_down(i - 1);
        }

        T result = std::move(heap_[0].item);
        heap_[0] = std::move(heap_.back());
        heap_.pop_back();
        if (!heap_.empty()) heapify_down(0);
        return result;
    }

    bool empty() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return heap_.empty();
    }
};
```

**Day 1-2 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] å®ç°ä¼˜å…ˆçº§çº¿ç¨‹æ± 
- [ ] ç†è§£ä¼˜å…ˆçº§åè½¬å’Œé¥¥é¥¿é—®é¢˜
- [ ] å®ç°é˜²é¥¥é¥¿çš„è€åŒ–æœºåˆ¶

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `priority_thread_pool.hpp`
- [ ] `aging_priority_queue.hpp`
- [ ] ç¬”è®°ï¼š`notes/week3/day1-2_priority_scheduling.md`

---

#### ğŸ“… Day 3-4: ä»»åŠ¡ä¾èµ–å›¾ï¼ˆDAGï¼‰ï¼ˆ10å°æ—¶ï¼‰

**Day 3ï¼ˆ5å°æ—¶ï¼‰- ä»»åŠ¡ä¾èµ–å›¾è®¾è®¡**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | DAG æ¦‚å¿µ | ç†è§£æœ‰å‘æ— ç¯å›¾åœ¨ä»»åŠ¡è°ƒåº¦ä¸­çš„åº”ç”¨ |
| 1:30-3:00 | æ‹“æ‰‘æ’åº | å®ç° Kahn ç®—æ³• |
| 3:00-5:00 | æ•°æ®ç»“æ„è®¾è®¡ | è®¾è®¡ä»»åŠ¡ä¾èµ–å›¾çš„æ•°æ®ç»“æ„ |

**æ ¸å¿ƒæ¦‚å¿µï¼šä»»åŠ¡ä¾èµ–å›¾**
```
ä»»åŠ¡ä¾èµ–ç¤ºä¾‹ï¼šç¼–è¯‘é¡¹ç›®

    â”Œâ”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”
    â”‚ A.o â”‚     â”‚ B.o â”‚
    â””â”€â”€â”¬â”€â”€â”˜     â””â”€â”€â”¬â”€â”€â”˜
       â”‚           â”‚
       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  link   â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚
             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   run   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

A.o å’Œ B.o å¯ä»¥å¹¶è¡Œç¼–è¯‘
link ä¾èµ–äº A.o å’Œ B.o
run ä¾èµ–äº link
```

**åŠ¨æ‰‹å®éªŒ 3-3ï¼šä»»åŠ¡ä¾èµ–å›¾**
```cpp
// task_graph.hpp
#pragma once
#include <unordered_map>
#include <unordered_set>
#include <vector>
#include <functional>
#include <future>
#include <mutex>
#include <queue>
#include <atomic>

class TaskGraph {
public:
    using TaskId = size_t;
    using TaskFunc = std::function<void()>;

private:
    struct TaskNode {
        TaskId id;
        TaskFunc func;
        std::vector<TaskId> dependencies;  // ä¾èµ–çš„ä»»åŠ¡
        std::vector<TaskId> dependents;    // ä¾èµ–æ­¤ä»»åŠ¡çš„ä»»åŠ¡
        std::atomic<size_t> pending_deps{0};  // æœªå®Œæˆçš„ä¾èµ–æ•°
        std::promise<void> completion;
        std::shared_future<void> future;

        TaskNode(TaskId id, TaskFunc func)
            : id(id), func(std::move(func)) {
            future = completion.get_future().share();
        }
    };

    std::unordered_map<TaskId, std::unique_ptr<TaskNode>> nodes_;
    std::mutex mutex_;
    std::atomic<TaskId> next_id_{0};

    // å°±ç»ªé˜Ÿåˆ—ï¼šæ— ä¾èµ–æˆ–ä¾èµ–å·²å®Œæˆçš„ä»»åŠ¡
    std::queue<TaskId> ready_queue_;
    std::mutex ready_mutex_;
    std::condition_variable ready_cv_;

public:
    // æ·»åŠ ä»»åŠ¡
    TaskId add_task(TaskFunc func) {
        TaskId id = next_id_++;
        std::lock_guard<std::mutex> lock(mutex_);
        nodes_[id] = std::make_unique<TaskNode>(id, std::move(func));
        return id;
    }

    // æ·»åŠ ä¾èµ–å…³ç³»ï¼štask ä¾èµ–äº dependency
    void add_dependency(TaskId task, TaskId dependency) {
        std::lock_guard<std::mutex> lock(mutex_);

        auto task_it = nodes_.find(task);
        auto dep_it = nodes_.find(dependency);
        if (task_it == nodes_.end() || dep_it == nodes_.end()) {
            throw std::runtime_error("Invalid task ID");
        }

        task_it->second->dependencies.push_back(dependency);
        dep_it->second->dependents.push_back(task);
    }

    // æ‰§è¡Œå›¾ä¸­æ‰€æœ‰ä»»åŠ¡
    void execute(size_t num_threads = std::thread::hardware_concurrency()) {
        // 1. è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„å¾…å®Œæˆä¾èµ–æ•°
        {
            std::lock_guard<std::mutex> lock(mutex_);
            for (auto& [id, node] : nodes_) {
                node->pending_deps = node->dependencies.size();
                if (node->pending_deps == 0) {
                    std::lock_guard<std::mutex> rlock(ready_mutex_);
                    ready_queue_.push(id);
                }
            }
        }

        // 2. å¯åŠ¨å·¥ä½œçº¿ç¨‹
        std::atomic<bool> done{false};
        std::atomic<size_t> completed{0};
        size_t total = nodes_.size();

        std::vector<std::thread> workers;
        for (size_t i = 0; i < num_threads; ++i) {
            workers.emplace_back([this, &done, &completed, total]() {
                while (!done || completed < total) {
                    TaskId task_id;
                    {
                        std::unique_lock<std::mutex> lock(ready_mutex_);
                        ready_cv_.wait_for(lock, std::chrono::milliseconds(10),
                            [this] { return !ready_queue_.empty(); });

                        if (ready_queue_.empty()) continue;

                        task_id = ready_queue_.front();
                        ready_queue_.pop();
                    }

                    // æ‰§è¡Œä»»åŠ¡
                    auto& node = nodes_[task_id];
                    try {
                        node->func();
                    } catch (...) {}

                    node->completion.set_value();
                    ++completed;

                    // æ›´æ–°ä¾èµ–æ­¤ä»»åŠ¡çš„ä»»åŠ¡
                    for (TaskId dep_id : node->dependents) {
                        auto& dep_node = nodes_[dep_id];
                        if (--dep_node->pending_deps == 0) {
                            std::lock_guard<std::mutex> lock(ready_mutex_);
                            ready_queue_.push(dep_id);
                            ready_cv_.notify_one();
                        }
                    }
                }
            });
        }

        done = true;
        ready_cv_.notify_all();

        for (auto& w : workers) {
            if (w.joinable()) w.join();
        }
    }

    // ç­‰å¾…ç‰¹å®šä»»åŠ¡å®Œæˆ
    void wait(TaskId id) {
        std::lock_guard<std::mutex> lock(mutex_);
        if (nodes_.find(id) != nodes_.end()) {
            nodes_[id]->future.wait();
        }
    }

    // æ£€æµ‹å¾ªç¯ä¾èµ–
    bool has_cycle() const {
        std::unordered_map<TaskId, int> in_degree;
        for (const auto& [id, node] : nodes_) {
            in_degree[id] = node->dependencies.size();
        }

        std::queue<TaskId> zero_degree;
        for (const auto& [id, degree] : in_degree) {
            if (degree == 0) zero_degree.push(id);
        }

        size_t processed = 0;
        while (!zero_degree.empty()) {
            TaskId id = zero_degree.front();
            zero_degree.pop();
            ++processed;

            for (TaskId dep_id : nodes_.at(id)->dependents) {
                if (--in_degree[dep_id] == 0) {
                    zero_degree.push(dep_id);
                }
            }
        }

        return processed != nodes_.size();
    }
};
```

**Day 4ï¼ˆ5å°æ—¶ï¼‰- æµ‹è¯•ä¸ä¼˜åŒ–**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | æµ‹è¯•ç”¨ä¾‹ | ç¼–å†™å¤æ‚ä¾èµ–å›¾çš„æµ‹è¯• |
| 2:00-4:00 | å¾ªç¯æ£€æµ‹ | ç¡®ä¿æ£€æµ‹å¹¶æŠ¥å‘Šå¾ªç¯ä¾èµ– |
| 4:00-5:00 | æ€§èƒ½ä¼˜åŒ– | åˆ†æå¹¶ä¼˜åŒ–è°ƒåº¦å¼€é”€ |

**Day 3-4 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] ç†è§£ DAG åœ¨ä»»åŠ¡è°ƒåº¦ä¸­çš„åº”ç”¨
- [ ] å®ç°ä»»åŠ¡ä¾èµ–å›¾
- [ ] æ­£ç¡®æ£€æµ‹å¾ªç¯ä¾èµ–

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `task_graph.hpp`
- [ ] `test_task_graph.cpp`
- [ ] ç¬”è®°ï¼š`notes/week3/day3-4_task_dag.md`

---

#### ğŸ“… Day 5-6: å»¶è¿Ÿä»»åŠ¡ä¸å®šæ—¶æ‰§è¡Œï¼ˆ10å°æ—¶ï¼‰

**Day 5ï¼ˆ5å°æ—¶ï¼‰- å®šæ—¶ä»»åŠ¡è®¾è®¡**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | å®šæ—¶å™¨è®¾è®¡ | åˆ†æå®šæ—¶ä»»åŠ¡çš„å®ç°æ–¹å¼ |
| 2:00-3:30 | æ—¶é—´è½®ç®—æ³• | å­¦ä¹  Timing Wheel ç®—æ³• |
| 3:30-5:00 | åŸºç¡€å®ç° | å®ç°ç®€å•çš„å»¶è¿Ÿé˜Ÿåˆ— |

**æ ¸å¿ƒæ¦‚å¿µï¼šå®šæ—¶ä»»åŠ¡å®ç°æ–¹å¼**
```cpp
/*
å®šæ—¶ä»»åŠ¡å®ç°æ–¹å¼å¯¹æ¯”ï¼š

1. æœ€å°å †ï¼ˆstd::priority_queueï¼‰
   - ä¼˜ç‚¹ï¼šç®€å•ï¼ŒæŒ‰è§¦å‘æ—¶é—´æ’åº
   - ç¼ºç‚¹ï¼šæ’å…¥ O(log n)ï¼Œå¯èƒ½æœ‰æ€§èƒ½é—®é¢˜
   - é€‚ç”¨ï¼šä»»åŠ¡æ•°é‡ä¸å¤§æ—¶

2. æ—¶é—´è½®ï¼ˆTiming Wheelï¼‰
   - ä¼˜ç‚¹ï¼šæ’å…¥åˆ é™¤ O(1)
   - ç¼ºç‚¹ï¼šç²¾åº¦å—é™äºè½®çš„ç²’åº¦
   - é€‚ç”¨ï¼šé«˜ååé‡å®šæ—¶ä»»åŠ¡

3. åˆ†å±‚æ—¶é—´è½®ï¼ˆHierarchical Timing Wheelï¼‰
   - ä¼˜ç‚¹ï¼šå…¼é¡¾ç²¾åº¦å’Œæ€§èƒ½
   - ç¼ºç‚¹ï¼šå®ç°å¤æ‚
   - é€‚ç”¨ï¼šéœ€è¦è¦†ç›–å¤§æ—¶é—´èŒƒå›´
*/
```

**åŠ¨æ‰‹å®éªŒ 3-4ï¼šå»¶è¿Ÿä»»åŠ¡é˜Ÿåˆ—**
```cpp
// scheduled_thread_pool.hpp
#pragma once
#include <thread>
#include <queue>
#include <functional>
#include <chrono>
#include <mutex>
#include <condition_variable>
#include <atomic>

class ScheduledThreadPool {
public:
    using Clock = std::chrono::steady_clock;
    using TimePoint = Clock::time_point;
    using Duration = Clock::duration;

private:
    struct ScheduledTask {
        TimePoint execute_at;
        std::function<void()> task;
        std::optional<Duration> period;  // å‘¨æœŸä»»åŠ¡
        uint64_t sequence;

        bool operator>(const ScheduledTask& other) const {
            if (execute_at != other.execute_at) {
                return execute_at > other.execute_at;
            }
            return sequence > other.sequence;
        }
    };

    std::priority_queue<ScheduledTask, std::vector<ScheduledTask>,
                        std::greater<ScheduledTask>> tasks_;
    std::vector<std::thread> workers_;
    std::mutex mutex_;
    std::condition_variable cv_;
    std::atomic<bool> stop_{false};
    std::atomic<uint64_t> sequence_{0};

    void scheduler_loop() {
        while (!stop_) {
            std::unique_lock<std::mutex> lock(mutex_);

            if (tasks_.empty()) {
                cv_.wait(lock, [this] { return stop_ || !tasks_.empty(); });
                continue;
            }

            auto& top = tasks_.top();
            auto now = Clock::now();

            if (top.execute_at <= now) {
                // ä»»åŠ¡å°±ç»ª
                ScheduledTask task = std::move(const_cast<ScheduledTask&>(top));
                tasks_.pop();
                lock.unlock();

                // æ‰§è¡Œä»»åŠ¡
                try { task.task(); } catch (...) {}

                // å¦‚æœæ˜¯å‘¨æœŸä»»åŠ¡ï¼Œé‡æ–°è°ƒåº¦
                if (task.period) {
                    lock.lock();
                    task.execute_at = Clock::now() + *task.period;
                    task.sequence = sequence_++;
                    tasks_.push(std::move(task));
                }
            } else {
                // ç­‰å¾…åˆ°ä¸‹ä¸€ä¸ªä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´
                cv_.wait_until(lock, top.execute_at);
            }
        }
    }

public:
    explicit ScheduledThreadPool(size_t threads = 1) {
        for (size_t i = 0; i < threads; ++i) {
            workers_.emplace_back(&ScheduledThreadPool::scheduler_loop, this);
        }
    }

    ~ScheduledThreadPool() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            stop_ = true;
        }
        cv_.notify_all();
        for (auto& w : workers_) if (w.joinable()) w.join();
    }

    // å»¶è¿Ÿæ‰§è¡Œ
    void schedule(std::function<void()> task, Duration delay) {
        std::lock_guard<std::mutex> lock(mutex_);
        tasks_.push(ScheduledTask{
            Clock::now() + delay,
            std::move(task),
            std::nullopt,
            sequence_++
        });
        cv_.notify_one();
    }

    // åœ¨æŒ‡å®šæ—¶é—´æ‰§è¡Œ
    void schedule_at(std::function<void()> task, TimePoint time) {
        std::lock_guard<std::mutex> lock(mutex_);
        tasks_.push(ScheduledTask{
            time,
            std::move(task),
            std::nullopt,
            sequence_++
        });
        cv_.notify_one();
    }

    // å‘¨æœŸæ‰§è¡Œ
    void schedule_periodic(std::function<void()> task,
                          Duration initial_delay, Duration period) {
        std::lock_guard<std::mutex> lock(mutex_);
        tasks_.push(ScheduledTask{
            Clock::now() + initial_delay,
            std::move(task),
            period,
            sequence_++
        });
        cv_.notify_one();
    }
};
```

**Day 6ï¼ˆ5å°æ—¶ï¼‰- æ—¶é—´è½®å®ç°**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-3:00 | æ—¶é—´è½®å®ç° | å®ç°ç®€å•æ—¶é—´è½® |
| 3:00-5:00 | æ€§èƒ½å¯¹æ¯” | å¯¹æ¯”å †å®ç°å’Œæ—¶é—´è½®çš„æ€§èƒ½ |

**Day 5-6 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] å®ç°å»¶è¿Ÿä»»åŠ¡è°ƒåº¦
- [ ] å®ç°å‘¨æœŸä»»åŠ¡è°ƒåº¦
- [ ] ç†è§£æ—¶é—´è½®ç®—æ³•çš„ä¼˜åŠ¿

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `scheduled_thread_pool.hpp`
- [ ] `test_scheduled_pool.cpp`
- [ ] ç¬”è®°ï¼š`notes/week3/day5-6_delayed_tasks.md`

---

#### ğŸ“… Day 7: ç¬¬ä¸‰å‘¨æ€»ç»“ï¼ˆ5å°æ—¶ï¼‰

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | æºç é˜…è¯» | é˜…è¯» Java ScheduledThreadPoolExecutor |
| 2:00-4:00 | ç»¼åˆå®è·µ | æ•´åˆä¼˜å…ˆçº§ã€ä¾èµ–ã€å®šæ—¶åŠŸèƒ½ |
| 4:00-5:00 | ç¬”è®°æ•´ç† | æ•´ç†æœ¬å‘¨å­¦ä¹ ç¬”è®° |

**ç¬¬ä¸‰å‘¨è¾“å‡ºç‰©æ±‡æ€»**ï¼š
1. `priority_thread_pool.hpp` - ä¼˜å…ˆçº§çº¿ç¨‹æ± 
2. `aging_priority_queue.hpp` - å¸¦è€åŒ–çš„ä¼˜å…ˆçº§é˜Ÿåˆ—
3. `task_graph.hpp` - ä»»åŠ¡ä¾èµ–å›¾
4. `scheduled_thread_pool.hpp` - å®šæ—¶ä»»åŠ¡çº¿ç¨‹æ± 
5. `test_*.cpp` - æµ‹è¯•æ–‡ä»¶
6. `notes/week3/` - æœ¬å‘¨ç¬”è®°

---

### ç¬¬å››å‘¨ï¼šåŠ¨æ€æ‰©ç¼©å®¹ä¸ç”Ÿäº§çº§ç‰¹æ€§

**å­¦ä¹ ç›®æ ‡**ï¼šå®ç°è‡ªé€‚åº”çº¿ç¨‹æ± ï¼ŒæŒæ¡ç›‘æ§ä¸è°ƒä¼˜æŠ€æœ¯

**é˜…è¯»ææ–™**ï¼š
- [ ] Java ThreadPoolExecutor æºç ï¼ˆåŠ¨æ€çº¿ç¨‹ç®¡ç†éƒ¨åˆ†ï¼‰
- [ ] folly::CPUThreadPoolExecutor è®¾è®¡æ–‡æ¡£
- [ ] CppCon 2019: "Back to Basics: Concurrency" by Arthur O'Dwyer

---

#### ğŸ“… Day 1-2: åŠ¨æ€çº¿ç¨‹æ•°è°ƒæ•´ï¼ˆ10å°æ—¶ï¼‰

**Day 1ï¼ˆ5å°æ—¶ï¼‰- åŠ¨æ€æ‰©ç¼©å®¹ç­–ç•¥**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-1:30 | ç­–ç•¥åˆ†æ | å­¦ä¹ ä½•æ—¶æ‰©å®¹ã€ä½•æ—¶ç¼©å®¹çš„åˆ¤æ–­æ ‡å‡† |
| 1:30-3:00 | å‚æ•°è®¾è®¡ | è®¾è®¡ core/max çº¿ç¨‹æ•°ã€keepAlive æ—¶é—´ç­‰å‚æ•° |
| 3:00-5:00 | åŸºç¡€å®ç° | å®ç°åŠ¨æ€çº¿ç¨‹æ•°è°ƒæ•´æ¡†æ¶ |

**æ ¸å¿ƒæ¦‚å¿µï¼šåŠ¨æ€çº¿ç¨‹æ± å‚æ•°**
```cpp
/*
Java ThreadPoolExecutor çš„æ ¸å¿ƒå‚æ•°ï¼š

1. corePoolSizeï¼ˆæ ¸å¿ƒçº¿ç¨‹æ•°ï¼‰
   - å³ä½¿ç©ºé—²ä¹Ÿä¿ç•™çš„çº¿ç¨‹æ•°
   - ä¿è¯æœ€å°å“åº”èƒ½åŠ›

2. maximumPoolSizeï¼ˆæœ€å¤§çº¿ç¨‹æ•°ï¼‰
   - å…è®¸åˆ›å»ºçš„æœ€å¤§çº¿ç¨‹æ•°
   - é˜²æ­¢èµ„æºè€—å°½

3. keepAliveTimeï¼ˆç©ºé—²è¶…æ—¶ï¼‰
   - è¶…è¿‡ core çš„çº¿ç¨‹ç©ºé—²å¤šä¹…åå›æ”¶
   - å¹³è¡¡èµ„æºåˆ©ç”¨å’Œå“åº”èƒ½åŠ›

4. workQueueï¼ˆä»»åŠ¡é˜Ÿåˆ—ï¼‰
   - æœ‰ç•Œ vs æ— ç•Œ
   - å½±å“æ‰©å®¹æ—¶æœº

æ‰©ç¼©å®¹ç­–ç•¥ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æäº¤ä»»åŠ¡                                               â”‚
â”‚      â”‚                                                  â”‚
â”‚      â–¼                                                  â”‚
â”‚  å½“å‰çº¿ç¨‹ < corePoolSize?  â”€â”€Yesâ”€â”€â–¶  åˆ›å»ºæ ¸å¿ƒçº¿ç¨‹æ‰§è¡Œ   â”‚
â”‚      â”‚No                                                â”‚
â”‚      â–¼                                                  â”‚
â”‚  é˜Ÿåˆ—æœªæ»¡?  â”€â”€Yesâ”€â”€â–¶  åŠ å…¥é˜Ÿåˆ—                          â”‚
â”‚      â”‚No                                                â”‚
â”‚      â–¼                                                  â”‚
â”‚  å½“å‰çº¿ç¨‹ < maximumPoolSize?  â”€â”€Yesâ”€â”€â–¶  åˆ›å»ºä¸´æ—¶çº¿ç¨‹    â”‚
â”‚      â”‚No                                                â”‚
â”‚      â–¼                                                  â”‚
â”‚  æ‰§è¡Œæ‹’ç»ç­–ç•¥                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
*/
```

**åŠ¨æ‰‹å®éªŒ 4-1ï¼šè‡ªé€‚åº”çº¿ç¨‹æ± **
```cpp
// adaptive_thread_pool.hpp
#pragma once
#include <thread>
#include <vector>
#include <queue>
#include <functional>
#include <future>
#include <mutex>
#include <condition_variable>
#include <atomic>
#include <chrono>

class AdaptiveThreadPool {
public:
    struct Config {
        size_t core_threads = 2;        // æ ¸å¿ƒçº¿ç¨‹æ•°
        size_t max_threads = 8;         // æœ€å¤§çº¿ç¨‹æ•°
        std::chrono::seconds keep_alive{60};  // ç©ºé—²è¶…æ—¶
        size_t queue_capacity = 1000;   // é˜Ÿåˆ—å®¹é‡
    };

    enum class RejectionPolicy {
        Abort,      // æŠ›å‡ºå¼‚å¸¸
        CallerRuns, // è°ƒç”¨è€…æ‰§è¡Œ
        Discard,    // ä¸¢å¼ƒä»»åŠ¡
        DiscardOldest  // ä¸¢å¼ƒæœ€è€ä»»åŠ¡
    };

private:
    struct Worker {
        std::thread thread;
        std::chrono::steady_clock::time_point last_active;
        bool is_core;
    };

    Config config_;
    RejectionPolicy rejection_policy_ = RejectionPolicy::Abort;

    std::queue<std::function<void()>> tasks_;
    std::vector<std::unique_ptr<Worker>> workers_;
    std::mutex mutex_;
    std::condition_variable cv_;
    std::condition_variable worker_cv_;  // ç”¨äºå”¤é†’ç©ºé—²æ£€æŸ¥

    std::atomic<bool> stop_{false};
    std::atomic<size_t> active_threads_{0};
    std::atomic<size_t> total_threads_{0};

    void worker_loop(Worker* self) {
        while (!stop_) {
            std::function<void()> task;
            {
                std::unique_lock<std::mutex> lock(mutex_);

                // éæ ¸å¿ƒçº¿ç¨‹æœ‰è¶…æ—¶
                auto timeout = self->is_core ?
                    std::chrono::steady_clock::time_point::max() :
                    self->last_active + config_.keep_alive;

                bool got_task = cv_.wait_until(lock, timeout, [this] {
                    return stop_ || !tasks_.empty();
                });

                if (stop_ && tasks_.empty()) {
                    --total_threads_;
                    return;
                }

                if (!got_task && !self->is_core) {
                    // è¶…æ—¶ä¸”æ˜¯éæ ¸å¿ƒçº¿ç¨‹ï¼Œé€€å‡º
                    --total_threads_;
                    return;
                }

                if (tasks_.empty()) continue;

                task = std::move(tasks_.front());
                tasks_.pop();
                self->last_active = std::chrono::steady_clock::now();
            }

            if (task) {
                ++active_threads_;
                try { task(); } catch (...) {}
                --active_threads_;
            }
        }
        --total_threads_;
    }

    bool try_add_worker(bool is_core) {
        auto worker = std::make_unique<Worker>();
        worker->is_core = is_core;
        worker->last_active = std::chrono::steady_clock::now();

        Worker* ptr = worker.get();
        worker->thread = std::thread(&AdaptiveThreadPool::worker_loop, this, ptr);
        workers_.push_back(std::move(worker));
        ++total_threads_;
        return true;
    }

    void handle_rejection(std::function<void()>& task) {
        switch (rejection_policy_) {
            case RejectionPolicy::Abort:
                throw std::runtime_error("Task rejected: queue full");
            case RejectionPolicy::CallerRuns:
                task();  // åœ¨å½“å‰çº¿ç¨‹æ‰§è¡Œ
                break;
            case RejectionPolicy::Discard:
                break;  // ç›´æ¥ä¸¢å¼ƒ
            case RejectionPolicy::DiscardOldest:
                if (!tasks_.empty()) {
                    tasks_.pop();
                    tasks_.push(std::move(task));
                }
                break;
        }
    }

public:
    explicit AdaptiveThreadPool(Config config = Config{})
        : config_(config) {
        // é¢„åˆ›å»ºæ ¸å¿ƒçº¿ç¨‹
        for (size_t i = 0; i < config_.core_threads; ++i) {
            std::lock_guard<std::mutex> lock(mutex_);
            try_add_worker(true);
        }
    }

    ~AdaptiveThreadPool() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            stop_ = true;
        }
        cv_.notify_all();
        for (auto& worker : workers_) {
            if (worker->thread.joinable()) {
                worker->thread.join();
            }
        }
    }

    void set_rejection_policy(RejectionPolicy policy) {
        rejection_policy_ = policy;
    }

    template <typename F, typename... Args>
    auto submit(F&& f, Args&&... args)
        -> std::future<std::invoke_result_t<F, Args...>>
    {
        using R = std::invoke_result_t<F, Args...>;
        auto task = std::make_shared<std::packaged_task<R()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        std::future<R> result = task->get_future();

        std::function<void()> wrapped = [task]() { (*task)(); };

        {
            std::lock_guard<std::mutex> lock(mutex_);

            // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ–°çº¿ç¨‹
            size_t current = total_threads_.load();
            size_t queue_size = tasks_.size();

            if (current < config_.core_threads) {
                // è¿˜æ²¡è¾¾åˆ°æ ¸å¿ƒçº¿ç¨‹æ•°ï¼Œåˆ›å»ºæ ¸å¿ƒçº¿ç¨‹
                try_add_worker(true);
            } else if (queue_size >= config_.queue_capacity) {
                // é˜Ÿåˆ—æ»¡äº†
                if (current < config_.max_threads) {
                    // è¿˜èƒ½åˆ›å»ºä¸´æ—¶çº¿ç¨‹
                    try_add_worker(false);
                } else {
                    // è¾¾åˆ°æœ€å¤§çº¿ç¨‹æ•°ï¼Œæ‰§è¡Œæ‹’ç»ç­–ç•¥
                    handle_rejection(wrapped);
                    return result;
                }
            } else if (queue_size > current * 2 && current < config_.max_threads) {
                // é˜Ÿåˆ—ç§¯å‹ä¸¥é‡ï¼Œä¸»åŠ¨æ‰©å®¹
                try_add_worker(false);
            }

            tasks_.push(std::move(wrapped));
        }
        cv_.notify_one();
        return result;
    }

    // ç›‘æ§æ¥å£
    size_t active_count() const { return active_threads_.load(); }
    size_t pool_size() const { return total_threads_.load(); }
    size_t queue_size() const {
        std::lock_guard<std::mutex> lock(const_cast<std::mutex&>(mutex_));
        return tasks_.size();
    }
};
```

**Day 2ï¼ˆ5å°æ—¶ï¼‰- æµ‹è¯•ä¸è°ƒä¼˜**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | è´Ÿè½½æµ‹è¯• | æ¨¡æ‹Ÿå„ç§è´Ÿè½½æ¨¡å¼æµ‹è¯•æ‰©ç¼©å®¹ |
| 2:00-4:00 | å‚æ•°è°ƒä¼˜ | åˆ†æä¸åŒå‚æ•°ç»„åˆçš„æ•ˆæœ |
| 4:00-5:00 | é—®é¢˜ä¿®å¤ | ä¿®å¤çº¿ç¨‹æ³„æ¼ç­‰é—®é¢˜ |

**Day 1-2 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] å®ç°åŠ¨æ€æ‰©å®¹å’Œç¼©å®¹
- [ ] ç†è§£å„ç§æ‹’ç»ç­–ç•¥çš„é€‚ç”¨åœºæ™¯
- [ ] èƒ½æ ¹æ®è´Ÿè½½æ¨¡å¼è°ƒæ•´å‚æ•°

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `adaptive_thread_pool.hpp`
- [ ] `test_adaptive_pool.cpp`
- [ ] ç¬”è®°ï¼š`notes/week4/day1-2_dynamic_scaling.md`

---

#### ğŸ“… Day 3-4: ç›‘æ§ä¸æ€§èƒ½è°ƒä¼˜ï¼ˆ10å°æ—¶ï¼‰

**Day 3ï¼ˆ5å°æ—¶ï¼‰- ç›‘æ§æŒ‡æ ‡æ”¶é›†**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | æŒ‡æ ‡è®¾è®¡ | ç¡®å®šéœ€è¦æ”¶é›†çš„æ€§èƒ½æŒ‡æ ‡ |
| 2:00-4:00 | å®ç°ç›‘æ§ | å®ç°æŒ‡æ ‡æ”¶é›†å’Œç»Ÿè®¡ |
| 4:00-5:00 | å¯è§†åŒ– | ç®€å•çš„æŒ‡æ ‡è¾“å‡º |

**æ ¸å¿ƒæ¦‚å¿µï¼šçº¿ç¨‹æ± å…³é”®æŒ‡æ ‡**
```cpp
/*
ç”Ÿäº§ç¯å¢ƒéœ€è¦ç›‘æ§çš„æŒ‡æ ‡ï¼š

1. ååé‡æŒ‡æ ‡
   - ä»»åŠ¡æäº¤é€Ÿç‡ï¼ˆtasks/secï¼‰
   - ä»»åŠ¡å®Œæˆé€Ÿç‡ï¼ˆtasks/secï¼‰
   - é˜Ÿåˆ—ç§¯å‹é‡

2. å»¶è¿ŸæŒ‡æ ‡
   - ä»»åŠ¡æ’é˜Ÿæ—¶é—´ï¼ˆä»æäº¤åˆ°å¼€å§‹æ‰§è¡Œï¼‰
   - ä»»åŠ¡æ‰§è¡Œæ—¶é—´
   - ç«¯åˆ°ç«¯å»¶è¿Ÿ

3. èµ„æºæŒ‡æ ‡
   - æ´»è·ƒçº¿ç¨‹æ•° / æ€»çº¿ç¨‹æ•°
   - é˜Ÿåˆ—ä½¿ç”¨ç‡
   - æ‹’ç»ä»»åŠ¡æ•°

4. å¼‚å¸¸æŒ‡æ ‡
   - ä»»åŠ¡å¤±è´¥æ•°
   - è¶…æ—¶ä»»åŠ¡æ•°
*/
```

**åŠ¨æ‰‹å®éªŒ 4-2ï¼šçº¿ç¨‹æ± ç›‘æ§**
```cpp
// thread_pool_metrics.hpp
#pragma once
#include <atomic>
#include <chrono>
#include <mutex>
#include <vector>
#include <cmath>

class ThreadPoolMetrics {
public:
    using Clock = std::chrono::steady_clock;
    using Duration = std::chrono::nanoseconds;

private:
    // è®¡æ•°å™¨
    std::atomic<uint64_t> submitted_tasks_{0};
    std::atomic<uint64_t> completed_tasks_{0};
    std::atomic<uint64_t> rejected_tasks_{0};
    std::atomic<uint64_t> failed_tasks_{0};

    // å»¶è¿Ÿç»Ÿè®¡ï¼ˆä½¿ç”¨æ»‘åŠ¨çª—å£ï¼‰
    struct LatencyStats {
        std::mutex mutex;
        std::vector<Duration> samples;
        size_t window_size = 1000;

        void record(Duration d) {
            std::lock_guard<std::mutex> lock(mutex);
            if (samples.size() >= window_size) {
                samples.erase(samples.begin());
            }
            samples.push_back(d);
        }

        Duration percentile(double p) const {
            std::lock_guard<std::mutex> lock(const_cast<std::mutex&>(mutex));
            if (samples.empty()) return Duration{0};

            std::vector<Duration> sorted = samples;
            std::sort(sorted.begin(), sorted.end());

            size_t idx = static_cast<size_t>(sorted.size() * p);
            if (idx >= sorted.size()) idx = sorted.size() - 1;
            return sorted[idx];
        }

        Duration mean() const {
            std::lock_guard<std::mutex> lock(const_cast<std::mutex&>(mutex));
            if (samples.empty()) return Duration{0};

            Duration sum{0};
            for (const auto& s : samples) sum += s;
            return sum / samples.size();
        }
    };

    LatencyStats queue_latency_;   // æ’é˜Ÿå»¶è¿Ÿ
    LatencyStats exec_latency_;    // æ‰§è¡Œå»¶è¿Ÿ

    // ååé‡ç»Ÿè®¡
    Clock::time_point start_time_ = Clock::now();

public:
    // è®°å½•äº‹ä»¶
    void task_submitted() { ++submitted_tasks_; }
    void task_completed() { ++completed_tasks_; }
    void task_rejected() { ++rejected_tasks_; }
    void task_failed() { ++failed_tasks_; }

    void record_queue_latency(Duration d) { queue_latency_.record(d); }
    void record_exec_latency(Duration d) { exec_latency_.record(d); }

    // æŸ¥è¯¢æŒ‡æ ‡
    uint64_t submitted_count() const { return submitted_tasks_.load(); }
    uint64_t completed_count() const { return completed_tasks_.load(); }
    uint64_t rejected_count() const { return rejected_tasks_.load(); }
    uint64_t failed_count() const { return failed_tasks_.load(); }

    double throughput() const {
        auto elapsed = std::chrono::duration_cast<std::chrono::seconds>(
            Clock::now() - start_time_).count();
        return elapsed > 0 ? static_cast<double>(completed_tasks_) / elapsed : 0;
    }

    // å»¶è¿Ÿç™¾åˆ†ä½
    Duration queue_latency_p50() const { return queue_latency_.percentile(0.5); }
    Duration queue_latency_p99() const { return queue_latency_.percentile(0.99); }
    Duration exec_latency_p50() const { return exec_latency_.percentile(0.5); }
    Duration exec_latency_p99() const { return exec_latency_.percentile(0.99); }

    // æ‰“å°æŠ¥å‘Š
    void print_report() const {
        auto to_ms = [](Duration d) {
            return std::chrono::duration_cast<std::chrono::microseconds>(d).count() / 1000.0;
        };

        std::cout << "=== Thread Pool Metrics ===\n"
                  << "Submitted: " << submitted_tasks_ << "\n"
                  << "Completed: " << completed_tasks_ << "\n"
                  << "Rejected:  " << rejected_tasks_ << "\n"
                  << "Failed:    " << failed_tasks_ << "\n"
                  << "Throughput: " << throughput() << " tasks/sec\n"
                  << "\nQueue Latency:\n"
                  << "  P50: " << to_ms(queue_latency_p50()) << " ms\n"
                  << "  P99: " << to_ms(queue_latency_p99()) << " ms\n"
                  << "\nExec Latency:\n"
                  << "  P50: " << to_ms(exec_latency_p50()) << " ms\n"
                  << "  P99: " << to_ms(exec_latency_p99()) << " ms\n";
    }
};
```

**Day 4ï¼ˆ5å°æ—¶ï¼‰- æ€§èƒ½è°ƒä¼˜å®è·µ**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | æ€§èƒ½åˆ†æ | ä½¿ç”¨ perf åˆ†æçº¿ç¨‹æ± æ€§èƒ½ |
| 2:00-4:00 | ä¼˜åŒ–å®è·µ | å‡å°‘é”ç«äº‰ã€ä¼˜åŒ–å†…å­˜åˆ†é… |
| 4:00-5:00 | åŸºå‡†å¯¹æ¯” | å¯¹æ¯”ä¼˜åŒ–å‰åçš„æ€§èƒ½ |

**Day 3-4 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] å®ç°å®Œæ•´çš„ç›‘æ§æŒ‡æ ‡æ”¶é›†
- [ ] èƒ½ä½¿ç”¨ perf åˆ†ææ€§èƒ½ç“¶é¢ˆ
- [ ] ç†è§£å¸¸è§çš„æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `thread_pool_metrics.hpp`
- [ ] `monitored_thread_pool.hpp`
- [ ] ç¬”è®°ï¼š`notes/week4/day3-4_monitoring.md`

---

#### ğŸ“… Day 5-6: ç”Ÿäº§çº§çº¿ç¨‹æ± æ•´åˆï¼ˆ10å°æ—¶ï¼‰

**Day 5ï¼ˆ5å°æ—¶ï¼‰- æ•´åˆæ‰€æœ‰ç‰¹æ€§**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-3:00 | ä»£ç æ•´åˆ | æ•´åˆå·¥ä½œçªƒå–ã€ä¼˜å…ˆçº§ã€ç›‘æ§ç­‰ç‰¹æ€§ |
| 3:00-5:00 | æ¥å£ä¼˜åŒ– | è®¾è®¡æ˜“ç”¨çš„ API |

**åŠ¨æ‰‹å®éªŒ 4-3ï¼šç”Ÿäº§çº§çº¿ç¨‹æ± **
```cpp
// production_thread_pool.hpp
#pragma once
#include <thread>
#include <vector>
#include <queue>
#include <functional>
#include <future>
#include <mutex>
#include <condition_variable>
#include <atomic>
#include <chrono>
#include <optional>
#include "thread_pool_metrics.hpp"

class ProductionThreadPool {
public:
    struct Config {
        size_t core_threads = std::thread::hardware_concurrency();
        size_t max_threads = std::thread::hardware_concurrency() * 2;
        std::chrono::seconds keep_alive{60};
        size_t queue_capacity = 10000;
        bool enable_work_stealing = true;
        bool enable_metrics = true;
    };

    enum class Priority { Low = 0, Normal = 1, High = 2, Critical = 3 };

private:
    struct Task {
        std::function<void()> func;
        Priority priority;
        std::chrono::steady_clock::time_point submit_time;
        uint64_t sequence;

        bool operator<(const Task& other) const {
            if (priority != other.priority) return priority < other.priority;
            return sequence > other.sequence;
        }
    };

    Config config_;
    std::priority_queue<Task> tasks_;
    std::vector<std::thread> workers_;
    mutable std::mutex mutex_;
    std::condition_variable cv_;
    std::atomic<bool> stop_{false};
    std::atomic<uint64_t> sequence_{0};
    std::atomic<size_t> active_count_{0};

    std::unique_ptr<ThreadPoolMetrics> metrics_;

    void worker_loop() {
        while (!stop_) {
            Task task;
            {
                std::unique_lock<std::mutex> lock(mutex_);
                cv_.wait(lock, [this] { return stop_ || !tasks_.empty(); });

                if (stop_ && tasks_.empty()) return;
                if (tasks_.empty()) continue;

                task = std::move(const_cast<Task&>(tasks_.top()));
                tasks_.pop();
            }

            // è®°å½•æ’é˜Ÿå»¶è¿Ÿ
            if (metrics_) {
                auto queue_time = std::chrono::steady_clock::now() - task.submit_time;
                metrics_->record_queue_latency(
                    std::chrono::duration_cast<std::chrono::nanoseconds>(queue_time));
            }

            ++active_count_;
            auto exec_start = std::chrono::steady_clock::now();

            try {
                task.func();
                if (metrics_) metrics_->task_completed();
            } catch (...) {
                if (metrics_) metrics_->task_failed();
            }

            // è®°å½•æ‰§è¡Œå»¶è¿Ÿ
            if (metrics_) {
                auto exec_time = std::chrono::steady_clock::now() - exec_start;
                metrics_->record_exec_latency(
                    std::chrono::duration_cast<std::chrono::nanoseconds>(exec_time));
            }

            --active_count_;
        }
    }

public:
    explicit ProductionThreadPool(Config config = Config{})
        : config_(config) {
        if (config_.enable_metrics) {
            metrics_ = std::make_unique<ThreadPoolMetrics>();
        }

        for (size_t i = 0; i < config_.core_threads; ++i) {
            workers_.emplace_back(&ProductionThreadPool::worker_loop, this);
        }
    }

    ~ProductionThreadPool() {
        shutdown();
    }

    void shutdown() {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            stop_ = true;
        }
        cv_.notify_all();
        for (auto& w : workers_) {
            if (w.joinable()) w.join();
        }
    }

    template <typename F, typename... Args>
    auto submit(F&& f, Args&&... args) {
        return submit(Priority::Normal, std::forward<F>(f), std::forward<Args>(args)...);
    }

    template <typename F, typename... Args>
    auto submit(Priority priority, F&& f, Args&&... args)
        -> std::future<std::invoke_result_t<F, Args...>>
    {
        using R = std::invoke_result_t<F, Args...>;
        auto task = std::make_shared<std::packaged_task<R()>>(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        std::future<R> result = task->get_future();

        {
            std::lock_guard<std::mutex> lock(mutex_);
            if (stop_) throw std::runtime_error("Pool is stopped");

            tasks_.push(Task{
                [task]() { (*task)(); },
                priority,
                std::chrono::steady_clock::now(),
                sequence_++
            });
        }

        if (metrics_) metrics_->task_submitted();
        cv_.notify_one();
        return result;
    }

    // ç›‘æ§æ¥å£
    const ThreadPoolMetrics* metrics() const { return metrics_.get(); }

    size_t active_count() const { return active_count_.load(); }
    size_t pool_size() const { return workers_.size(); }
    size_t queue_size() const {
        std::lock_guard<std::mutex> lock(mutex_);
        return tasks_.size();
    }
};
```

**Day 6ï¼ˆ5å°æ—¶ï¼‰- ç»¼åˆæµ‹è¯•ä¸æ–‡æ¡£**

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | ç»¼åˆæµ‹è¯• | ç¼–å†™å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ |
| 2:00-4:00 | å‹åŠ›æµ‹è¯• | é•¿æ—¶é—´é«˜è´Ÿè½½æµ‹è¯• |
| 4:00-5:00 | æ–‡æ¡£æ•´ç† | ç¼–å†™ä½¿ç”¨æ–‡æ¡£ |

**Day 5-6 æ£€éªŒæ ‡å‡†**ï¼š
- [ ] æ•´åˆæ‰€æœ‰ç‰¹æ€§åˆ°ç”Ÿäº§çº§çº¿ç¨‹æ± 
- [ ] é€šè¿‡å®Œæ•´çš„æµ‹è¯•å¥—ä»¶
- [ ] é€šè¿‡é•¿æ—¶é—´å‹åŠ›æµ‹è¯•

**ä»Šæ—¥è¾“å‡ºç‰©**ï¼š
- [ ] `production_thread_pool.hpp`
- [ ] `test_production_pool.cpp`
- [ ] `benchmark_suite.cpp`

---

#### ğŸ“… Day 7: ç¬¬å››å‘¨æ€»ç»“ä¸é¡¹ç›®æ”¶å°¾ï¼ˆ5å°æ—¶ï¼‰

| æ—¶é—´ | å†…å®¹ | å…·ä½“ä»»åŠ¡ |
|------|------|----------|
| 0:00-2:00 | å¯¹æ¯”åˆ†æ | ä¸ Java/Go/Rust çº¿ç¨‹æ± å®ç°å¯¹æ¯” |
| 2:00-3:30 | æœ€ä½³å®è·µ | æ€»ç»“çº¿ç¨‹æ± ä½¿ç”¨çš„æœ€ä½³å®è·µ |
| 3:30-5:00 | é¡¹ç›®æ•´ç† | æ•´ç†ä»£ç å’Œæ–‡æ¡£ |

**ä¸ä¸»æµå®ç°å¯¹æ¯”**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç‰¹æ€§         â”‚ æˆ‘ä»¬çš„å®ç°     â”‚ Java FJP     â”‚ Go Runtime   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å·¥ä½œçªƒå–     â”‚ âœ“              â”‚ âœ“            â”‚ âœ“            â”‚
â”‚ åŠ¨æ€æ‰©ç¼©å®¹   â”‚ âœ“              â”‚ âœ“            â”‚ âœ“            â”‚
â”‚ ä¼˜å…ˆçº§       â”‚ âœ“              â”‚ âœ—            â”‚ âœ—            â”‚
â”‚ ä»»åŠ¡ä¾èµ–     â”‚ âœ“              â”‚ âœ—            â”‚ âœ—            â”‚
â”‚ ç›‘æ§æŒ‡æ ‡     â”‚ âœ“              â”‚ âœ“            â”‚ å†…ç½®pprof    â”‚
â”‚ åç¨‹æ”¯æŒ     â”‚ âœ—              â”‚ âœ—            â”‚ âœ“            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç¬¬å››å‘¨è¾“å‡ºç‰©æ±‡æ€»**ï¼š
1. `adaptive_thread_pool.hpp` - è‡ªé€‚åº”çº¿ç¨‹æ± 
2. `thread_pool_metrics.hpp` - ç›‘æ§æŒ‡æ ‡
3. `production_thread_pool.hpp` - ç”Ÿäº§çº§çº¿ç¨‹æ± 
4. `test_*.cpp` / `benchmark_*.cpp` - æµ‹è¯•æ–‡ä»¶
5. `notes/week4/` - æœ¬å‘¨ç¬”è®°

---

## æ£€éªŒæ ‡å‡†

### çŸ¥è¯†æ£€éªŒ

- [ ] èƒ½è§£é‡Šçº¿ç¨‹æ± å››å¤§æ ¸å¿ƒç»„ä»¶çš„èŒè´£
- [ ] ç†è§£ future/promise/packaged_task çš„åŒºåˆ«å’Œè”ç³»
- [ ] èƒ½è§£é‡Šå·¥ä½œçªƒå–ç›¸æ¯”ä¼ ç»Ÿçº¿ç¨‹æ± çš„ä¼˜åŠ¿
- [ ] ç†è§£ Chase-Lev Deque çš„æ¯ä¸ªæ“ä½œåŠå…¶å†…å­˜åº
- [ ] ç†è§£ Fork/Join æ¨¡å¼çš„æ ¸å¿ƒæ€æƒ³
- [ ] èƒ½è§£é‡Šä¼˜å…ˆçº§åè½¬å’Œé¥¥é¥¿é—®é¢˜
- [ ] ç†è§£ DAG åœ¨ä»»åŠ¡è°ƒåº¦ä¸­çš„åº”ç”¨
- [ ] ç†è§£æ—¶é—´è½®ç®—æ³•çš„ä¼˜åŠ¿
- [ ] ç†è§£åŠ¨æ€æ‰©ç¼©å®¹çš„ç­–ç•¥å’Œå‚æ•°

### å®è·µæ£€éªŒ

- [ ] å®ç°åŸºç¡€çº¿ç¨‹æ± ï¼Œæ”¯æŒä»»åŠ¡æäº¤å’Œå…³é—­
- [ ] å®ç°è¿”å› future çš„ submit æ–¹æ³•
- [ ] å®ç°ä¼˜é›…å…³é—­å’Œç«‹å³å…³é—­
- [ ] å®ç° Chase-Lev æ— é” Deque
- [ ] å®ç°å·¥ä½œçªƒå–çº¿ç¨‹æ± 
- [ ] å®ç°ä¼˜å…ˆçº§çº¿ç¨‹æ± 
- [ ] å®ç°ä»»åŠ¡ä¾èµ–å›¾
- [ ] å®ç°å»¶è¿Ÿä»»åŠ¡è°ƒåº¦
- [ ] å®ç°åŠ¨æ€æ‰©ç¼©å®¹
- [ ] å®ç°ç›‘æ§æŒ‡æ ‡æ”¶é›†
- [ ] æ‰€æœ‰å®ç°é€šè¿‡ ThreadSanitizer æ£€æµ‹

### è¾“å‡ºç‰©æ¸…å•

**æ ¸å¿ƒä»£ç **ï¼š
1. `thread_safe_queue.hpp` - çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—
2. `basic_thread_pool.hpp` - åŸºç¡€çº¿ç¨‹æ± 
3. `thread_pool_with_future.hpp` - æ”¯æŒè¿”å›å€¼çš„çº¿ç¨‹æ± 
4. `lifecycle_thread_pool.hpp` - å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†
5. `simple_ws_deque.hpp` - ç®€åŒ–ç‰ˆå·¥ä½œçªƒå–é˜Ÿåˆ—
6. `chase_lev_deque.hpp` - æ— é” Chase-Lev Deque
7. `work_stealing_pool.hpp` - å·¥ä½œçªƒå–çº¿ç¨‹æ± 
8. `priority_thread_pool.hpp` - ä¼˜å…ˆçº§çº¿ç¨‹æ± 
9. `task_graph.hpp` - ä»»åŠ¡ä¾èµ–å›¾
10. `scheduled_thread_pool.hpp` - å®šæ—¶ä»»åŠ¡çº¿ç¨‹æ± 
11. `adaptive_thread_pool.hpp` - è‡ªé€‚åº”çº¿ç¨‹æ± 
12. `thread_pool_metrics.hpp` - ç›‘æ§æŒ‡æ ‡
13. `production_thread_pool.hpp` - ç”Ÿäº§çº§çº¿ç¨‹æ± 

**æµ‹è¯•ä¸åŸºå‡†**ï¼š
14. `test_*.cpp` - å•å…ƒæµ‹è¯•
15. `benchmark_*.cpp` - æ€§èƒ½åŸºå‡†æµ‹è¯•

**å­¦ä¹ ç¬”è®°**ï¼š
16. `notes/week1/` - ç¬¬ä¸€å‘¨ç¬”è®°
17. `notes/week2/` - ç¬¬äºŒå‘¨ç¬”è®°
18. `notes/week3/` - ç¬¬ä¸‰å‘¨ç¬”è®°
19. `notes/week4/` - ç¬¬å››å‘¨ç¬”è®°
20. `notes/month19_summary.md` - æœˆåº¦æ€»ç»“

---

## æ—¶é—´åˆ†é…ï¼ˆ140å°æ—¶/æœˆï¼‰

| å†…å®¹ | æ—¶é—´ | å æ¯” |
|------|------|------|
| ç†è®ºå­¦ä¹  | 35å°æ—¶ | 25% |
| ä»£ç å®ç° | 60å°æ—¶ | 43% |
| æµ‹è¯•è°ƒè¯• | 25å°æ—¶ | 18% |
| æºç é˜…è¯» | 10å°æ—¶ | 7% |
| ç¬”è®°æ•´ç† | 10å°æ—¶ | 7% |

---

## ä¸‹æœˆé¢„å‘Š

Month 20 å°†å­¦ä¹  **Actor æ¨¡å‹ä¸æ¶ˆæ¯ä¼ é€’**ï¼Œæ¢ç´¢å¦ä¸€ç§å¹¶å‘ç¼–ç¨‹èŒƒå¼ã€‚Actor æ¨¡å‹é€šè¿‡æ¶ˆæ¯ä¼ é€’è€Œéå…±äº«å†…å­˜æ¥å®ç°å¹¶å‘ï¼Œé¿å…äº†é”çš„å¤æ‚æ€§ï¼Œæ˜¯ Erlangã€Akka ç­‰ç³»ç»Ÿçš„æ ¸å¿ƒç†å¿µã€‚
